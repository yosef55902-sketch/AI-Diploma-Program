{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Data Loading and Exploration | ØªØ­Ù…ÙŠÙ„ ÙˆØ§Ø³ØªÙƒØ´Ø§Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "\n",
    "## ğŸ“š Prerequisites (What You Need First) | Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©\n",
    "\n",
    "**BEFORE starting this notebook**, you should have:\n",
    "- âœ… **Python 3.8+ installed** and working\n",
    "- âœ… **Basic Python knowledge**: Variables, data types, lists, dictionaries\n",
    "- âœ… **Libraries installed**: pandas, numpy, matplotlib, seaborn (see `requirements.txt`)\n",
    "- âœ… **Understanding of data**: What is a dataset? What are rows and columns?\n",
    "\n",
    "**If you haven't completed these**, you might struggle with:\n",
    "- Understanding DataFrame operations\n",
    "- Understanding data types and structures\n",
    "- Using pandas functions\n",
    "- Interpreting statistical summaries\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”— Where This Notebook Fits | Ù…ÙƒØ§Ù† Ù‡Ø°Ø§ Ø§Ù„Ø¯ÙØªØ±\n",
    "\n",
    "**This is the FIRST example** - it's the foundation for all data science!\n",
    "\n",
    "**Why this example FIRST?**\n",
    "- **Before** you can build ML models, you need to understand your data\n",
    "- **Before** you can clean data, you need to load and explore it\n",
    "- **Before** you can make predictions, you need to know what you're working with\n",
    "\n",
    "**Builds on**: \n",
    "- Python basics (variables, data structures)\n",
    "- Basic understanding of data files (CSV format)\n",
    "\n",
    "**Leads to**: \n",
    "- ğŸ““ Example 2: Data Cleaning (needs data exploration skills)\n",
    "- ğŸ““ Example 3: Data Preprocessing (needs data understanding)\n",
    "- ğŸ““ Example 4: Linear Regression (needs clean, explored data)\n",
    "- ğŸ““ All other ML examples (all need data exploration first!)\n",
    "\n",
    "**Why this order?**\n",
    "1. Data exploration teaches you **what you're working with** (needed for all ML)\n",
    "2. Data exploration shows you **data quality issues** (needed for cleaning)\n",
    "3. Data exploration helps you **understand relationships** (needed for modeling)\n",
    "\n",
    "---\n",
    "\n",
    "## The Story: Getting to Know Your Data | Ø§Ù„Ù‚ØµØ©: Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§ØªÙƒ\n",
    "\n",
    "Imagine you're a detective investigating a case. **Before** you can solve it, you need to examine all the evidence - look at it, understand what it means, check if anything is missing, and see how pieces connect. **After** exploring the evidence thoroughly, you can start building your case!\n",
    "\n",
    "Same with machine learning: **Before** building models, we explore our data - load it, examine its structure, check for problems, understand relationships. **After** thorough exploration, we can build accurate models!\n",
    "\n",
    "---\n",
    "\n",
    "## Why Data Exploration Matters | Ù„Ù…Ø§Ø°Ø§ ÙŠÙ‡Ù… Ø§Ø³ØªÙƒØ´Ø§Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§ØªØŸ\n",
    "\n",
    "Data exploration is the foundation of data science:\n",
    "- **Find Problems Early**: Missing values, duplicates, outliers\n",
    "- **Understand Structure**: What columns mean, what data types we have\n",
    "- **Discover Patterns**: Relationships between variables\n",
    "- **Make Informed Decisions**: Know what preprocessing is needed\n",
    "- **Save Time Later**: Catch issues before they break your models\n",
    "\n",
    "## Learning Objectives | Ø£Ù‡Ø¯Ø§Ù Ø§Ù„ØªØ¹Ù„Ù…\n",
    "1. Load data from CSV files using pandas\n",
    "2. Inspect data structure (shape, types, columns)\n",
    "3. Calculate basic statistics (mean, median, std)\n",
    "4. Identify missing values and duplicates\n",
    "5. Analyze categorical and numerical data\n",
    "6. Understand data quality before modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries imported successfully!\n",
      "\n",
      "ğŸ“š What each library does:\n",
      "   - pandas: Load, manipulate, and analyze data (our main tool!)\n",
      "   - numpy: Fast numerical computations (arrays, math)\n",
      "   - matplotlib: Create basic plots and charts\n",
      "   - seaborn: Create beautiful statistical visualizations\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "# These libraries help us work with data and create visualizations\n",
    "\n",
    "import pandas as pd  # For data manipulation and analysis (DataFrames, reading CSV)\n",
    "import numpy as np   # For numerical operations (arrays, math functions)\n",
    "import matplotlib.pyplot as plt  # For creating plots and visualizations\n",
    "import seaborn as sns  # For statistical visualizations (beautiful plots)\n",
    "\n",
    "print(\"âœ… Libraries imported successfully!\")\n",
    "print(\"\\nğŸ“š What each library does:\")\n",
    "print(\"   - pandas: Load, manipulate, and analyze data (our main tool!)\")\n",
    "print(\"   - numpy: Fast numerical computations (arrays, math)\")\n",
    "print(\"   - matplotlib: Create basic plots and charts\")\n",
    "print(\"   - seaborn: Create beautiful statistical visualizations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setting the Scene | Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø£ÙˆÙ„: Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø´Ù‡Ø¯\n",
    "\n",
    "**BEFORE**: We have raw data files (CSV) that we know nothing about.\n",
    "\n",
    "**AFTER**: We'll load the data, explore its structure, understand its quality, and be ready for the next steps (cleaning and modeling)!\n",
    "\n",
    "**Why this matters**: You can't build good models on bad data. Exploration helps us find and fix problems early!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Example 1: Data Loading and Exploration\n",
      "Ù…Ø«Ø§Ù„ 1: ØªØ­Ù…ÙŠÙ„ ÙˆØ§Ø³ØªÙƒØ´Ø§Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Set display options for better output\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "print(\"=\" * 60)\n",
    "print(\"Example 1: Data Loading and Exploration\")\n",
    "print(\"Ù…Ø«Ø§Ù„ 1: ØªØ­Ù…ÙŠÙ„ ÙˆØ§Ø³ØªÙƒØ´Ø§Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Loading Data from CSV | Ø§Ù„Ø®Ø·ÙˆØ© 1: ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ù…Ù„Ù CSV\n",
    "\n",
    "**BEFORE**: We have a CSV file but can't use it in Python.\n",
    "\n",
    "**AFTER**: We'll load it into a pandas DataFrame (a table-like structure) that we can work with!\n",
    "\n",
    "**Why CSV?** CSV (Comma-Separated Values) is the most common data format. Almost every dataset comes as CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Sample housing data created!\n",
      "   This represents 10 houses with their features\n",
      "   We'll use this to learn data exploration techniques\n"
     ]
    }
   ],
   "source": [
    "# Create sample data for demonstration\n",
    "# We'll create housing data to learn with\n",
    "# In real projects, you'd load this from a file\n",
    "\n",
    "# BEFORE: Just a Python dictionary (not easy to work with)\n",
    "# AFTER: We'll convert it to a DataFrame (pandas table - much easier!)\n",
    "\n",
    "data = {\n",
    "    'house_size': [1000, 1200, 1500, 1800, 2000, 2200, 2500, 2800, 3000, 3500],  # Square feet\n",
    "    'bedrooms': [2, 2, 3, 3, 3, 4, 4, 4, 5, 5],  # Number of bedrooms\n",
    "    'age': [5, 10, 8, 15, 3, 20, 12, 25, 7, 30],  # Years old\n",
    "    'price': [250000, 280000, 320000, 380000, 420000, 450000, 520000, 580000, 620000, 750000],  # Price in dollars\n",
    "    'location': ['A', 'B', 'A', 'C', 'B', 'C', 'A', 'C', 'B', 'A']  # Location code\n",
    "}\n",
    "\n",
    "# Convert dictionary to DataFrame\n",
    "# Why DataFrame? It's like Excel in Python - easy to work with!\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"ğŸ“Š Sample housing data created!\")\n",
    "print(\"   This represents 10 houses with their features\")\n",
    "print(\"   We'll use this to learn data exploration techniques\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV for demonstration\n",
    "df.to_csv('sample_housing_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Data loaded successfully!\n",
      "ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­!\n",
      "\n",
      "ğŸ“‹ What we loaded:\n",
      "   - File: sample_housing_data.csv\n",
      "   - Rows: 10\n",
      "   - Columns: 5\n",
      "   - Columns: house_size, bedrooms, age, price, location\n"
     ]
    }
   ],
   "source": [
    "# Load from CSV file\n",
    "# pd.read_csv() is the most common way to load data\n",
    "# Why read_csv? CSV is the standard format for data science!\n",
    "\n",
    "df_loaded = pd.read_csv('sample_housing_data.csv')\n",
    "\n",
    "print(\"\\nâœ… Data loaded successfully!\")\n",
    "print(\"ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­!\")\n",
    "print(f\"\\nğŸ“‹ What we loaded:\")\n",
    "print(f\"   - File: sample_housing_data.csv\")\n",
    "print(f\"   - Rows: {len(df_loaded)}\")\n",
    "print(f\"   - Columns: {len(df_loaded.columns)}\")\n",
    "print(f\"   - Columns: {', '.join(df_loaded.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Basic Data Inspection | Ø§Ù„Ø®Ø·ÙˆØ© 2: Ø§Ù„ÙØ­Øµ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "\n",
    "**BEFORE**: We loaded data but don't know what's inside.\n",
    "\n",
    "**AFTER**: We'll see the first/last rows, understand the structure, and know what we're working with!\n",
    "\n",
    "**Why inspect first?** You need to see your data before you can work with it. It's like opening a box before using what's inside!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“„ First 5 rows / Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ø®Ù…Ø³Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰:\n",
      "   (This gives us a quick look at what the data looks like)\n",
      "   house_size  bedrooms  age   price location\n",
      "0        1000         2    5  250000        A\n",
      "1        1200         2   10  280000        B\n",
      "2        1500         3    8  320000        A\n",
      "3        1800         3   15  380000        C\n",
      "4        2000         3    3  420000        B\n",
      "5        2200         4   20  450000        C\n",
      "6        2500         4   12  520000        A\n"
     ]
    }
   ],
   "source": [
    "# Display first few rows using .head()\n",
    "# Why .head()? It shows you a sample of your data without printing everything\n",
    "# Default shows 5 rows, but you can specify: .head(10) for 10 rows\n",
    "\n",
    "print(\"\\nğŸ“„ First 5 rows / Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ø®Ù…Ø³Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰:\")\n",
    "print(\"   (This gives us a quick look at what the data looks like)\")\n",
    "print(df_loaded.head(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last 5 rows / Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ø®Ù…Ø³Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø©:\n",
      "   house_size  bedrooms  age   price location\n",
      "5        2200         4   20  450000        C\n",
      "6        2500         4   12  520000        A\n",
      "7        2800         4   25  580000        C\n",
      "8        3000         5    7  620000        B\n",
      "9        3500         5   30  750000        A\n"
     ]
    }
   ],
   "source": [
    "# Display last few rows\n",
    "print(\"\\nLast 5 rows / Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ø®Ù…Ø³Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø©:\")\n",
    "print(df_loaded.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Data Shape / Ø´ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (ØµÙÙˆÙØŒ Ø£Ø¹Ù…Ø¯Ø©):\n",
      "   Rows: 10 (number of houses)\n",
      "   Columns: 5 (number of features)\n",
      "   Ø§Ù„ØµÙÙˆÙ: 10, Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©: 5\n"
     ]
    }
   ],
   "source": [
    "# Data shape (rows, columns)\n",
    "# .shape tells us the dimensions: (number_of_rows, number_of_columns)\n",
    "# Why check shape? It tells us how much data we have - important for understanding dataset size!\n",
    "\n",
    "print(\"\\nğŸ“ Data Shape / Ø´ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (ØµÙÙˆÙØŒ Ø£Ø¹Ù…Ø¯Ø©):\")\n",
    "print(f\"   Rows: {df_loaded.shape[0]} (number of houses)\")\n",
    "print(f\"   Columns: {df_loaded.shape[1]} (number of features)\")\n",
    "print(f\"   Ø§Ù„ØµÙÙˆÙ: {df_loaded.shape[0]}, Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©: {df_loaded.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistical summary for all numerical columns\n",
    "# .describe() gives us: count, mean, std, min, 25%, 50% (median), 75%, max\n",
    "# Why .describe()? It's a quick way to see all important statistics at once!\n",
    "\n",
    "print(\"\\nğŸ“Š Statistical Summary / Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠ:\")\n",
    "print(\"   (This shows mean, median, std, min, max for all numerical columns)\")\n",
    "print(df_loaded.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”¢ Data Types / Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:\n",
      "   (Understanding types helps us know how to process each column)\n",
      "house_size     int64\n",
      "bedrooms       int64\n",
      "age            int64\n",
      "price          int64\n",
      "location      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Data types for each column\n",
    "# .dtypes shows what type of data each column contains\n",
    "# Why check types? Different types need different handling:\n",
    "#   - int64/float64: Numbers (can do math)\n",
    "#   - object: Text/categories (need encoding for ML)\n",
    "\n",
    "print(\"\\nğŸ”¢ Data Types / Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:\")\n",
    "print(\"   (Understanding types helps us know how to process each column)\")\n",
    "print(df_loaded.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "# .isnull() returns True for missing values, False otherwise\n",
    "# .sum() counts how many True values (missing values) in each column\n",
    "# Why check missing values? ML models can't work with missing data - we need to handle them!\n",
    "\n",
    "missing_values = df_loaded.isnull().sum()\n",
    "total_missing = missing_values.sum()\n",
    "\n",
    "print(\"\\nğŸ” Missing Values Check / Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©:\")\n",
    "print(\"   (Shows how many missing values in each column)\")\n",
    "print(missing_values)\n",
    "\n",
    "if total_missing == 0:\n",
    "    print(\"\\n   âœ… No missing values found! Data is complete.\")\n",
    "    print(\"   âœ… Ù„Ø§ ØªÙˆØ¬Ø¯ Ù‚ÙŠÙ… Ù…ÙÙ‚ÙˆØ¯Ø©! Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§Ù…Ù„Ø©.\")\n",
    "else:\n",
    "    print(f\"\\n   âš ï¸  Found {total_missing} missing value(s) total\")\n",
    "    print(f\"   âš ï¸  ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {total_missing} Ù‚ÙŠÙ…Ø© Ù…ÙÙ‚ÙˆØ¯Ø©\")\n",
    "    print(\"   ğŸ’¡ We'll learn how to handle these in Example 2: Data Cleaning\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â„¹ï¸  Data Info / Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:\n",
      "   (This shows us data types AND if there are missing values)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   house_size  10 non-null     int64 \n",
      " 1   bedrooms    10 non-null     int64 \n",
      " 2   age         10 non-null     int64 \n",
      " 3   price       10 non-null     int64 \n",
      " 4   location    10 non-null     object\n",
      "dtypes: int64(4), object(1)\n",
      "memory usage: 528.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive data information\n",
    "# .info() gives us a summary: data types, non-null counts, memory usage\n",
    "# Why .info()? It's a quick health check - shows if we have missing values!\n",
    "\n",
    "print(\"\\nâ„¹ï¸  Data Info / Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:\")\n",
    "print(\"   (This shows us data types AND if there are missing values)\")\n",
    "print(df_loaded.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate rows\n",
    "# .duplicated() returns True for duplicate rows (rows that appear more than once)\n",
    "# .sum() counts how many duplicate rows we have\n",
    "# Why check duplicates? Duplicates can bias our models - same data counted twice!\n",
    "\n",
    "duplicate_count = df_loaded.duplicated().sum()\n",
    "\n",
    "print(\"\\nğŸ” Duplicate Rows Check / Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ù…ÙƒØ±Ø±Ø©:\")\n",
    "print(f\"   Number of duplicate rows: {duplicate_count}\")\n",
    "\n",
    "if duplicate_count == 0:\n",
    "    print(\"\\n   âœ… No duplicate rows found! Each row is unique.\")\n",
    "    print(\"   âœ… Ù„Ø§ ØªÙˆØ¬Ø¯ ØµÙÙˆÙ Ù…ÙƒØ±Ø±Ø©! ÙƒÙ„ ØµÙ ÙØ±ÙŠØ¯.\")\n",
    "else:\n",
    "    print(f\"\\n   âš ï¸  Found {duplicate_count} duplicate row(s)\")\n",
    "    print(f\"   âš ï¸  ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {duplicate_count} ØµÙ Ù…ÙƒØ±Ø±\")\n",
    "    print(\"   ğŸ’¡ We'll learn how to remove these in Example 2: Data Cleaning\")\n",
    "    \n",
    "    # Show duplicate rows if they exist\n",
    "    print(\"\\n   Duplicate rows:\")\n",
    "    print(df_loaded[df_loaded.duplicated()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Statistical Summary | Ø§Ù„Ø®Ø·ÙˆØ© 3: Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠ\n",
    "\n",
    "**BEFORE**: We see individual rows but don't understand the overall patterns.\n",
    "\n",
    "**AFTER**: We'll calculate statistics (mean, median, std) to understand the distribution of our data!\n",
    "\n",
    "**Why statistics?** They summarize your data in numbers:\n",
    "- **Mean**: Average value\n",
    "- **Median**: Middle value (less affected by outliers)\n",
    "- **Std**: How spread out the data is\n",
    "- **Min/Max**: Range of values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Check for Missing Values | Ø§Ù„Ø®Ø·ÙˆØ© 4: Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©\n",
    "\n",
    "**BEFORE**: We don't know if our data has gaps or missing information.\n",
    "\n",
    "**AFTER**: We'll identify any missing values that could cause problems in our models!\n",
    "\n",
    "**Why check for missing values?** \n",
    "- ML models can't work with missing data\n",
    "- Missing values indicate data quality issues\n",
    "- We need to handle them before modeling (fill, drop, or impute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze categorical data (location column)\n",
    "# .value_counts() counts how many times each category appears\n",
    "# Why analyze categorical data? Shows if categories are balanced or imbalanced!\n",
    "\n",
    "print(\"\\nğŸ“Š Categorical Data Analysis / ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙØ¦ÙˆÙŠØ©:\")\n",
    "print(\"   Location distribution / ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…ÙˆÙ‚Ø¹:\")\n",
    "\n",
    "location_counts = df_loaded['location'].value_counts()\n",
    "print(location_counts)\n",
    "\n",
    "print(\"\\n   Interpretation:\")\n",
    "print(f\"   - Total locations: {len(location_counts)}\")\n",
    "print(f\"   - Most common: {location_counts.index[0]} (appears {location_counts.iloc[0]} times)\")\n",
    "print(f\"   - Least common: {location_counts.index[-1]} (appears {location_counts.iloc[-1]} times)\")\n",
    "\n",
    "# Check if balanced\n",
    "if location_counts.max() - location_counts.min() <= 1:\n",
    "    print(\"\\n   âœ… Categories are balanced (similar counts)\")\n",
    "    print(\"   âœ… Ø§Ù„ÙØ¦Ø§Øª Ù…ØªÙˆØ§Ø²Ù†Ø© (Ø£Ø¹Ø¯Ø§Ø¯ Ù…ØªØ´Ø§Ø¨Ù‡Ø©)\")\n",
    "else:\n",
    "    print(\"\\n   âš ï¸  Categories are imbalanced (very different counts)\")\n",
    "    print(\"   âš ï¸  Ø§Ù„ÙØ¦Ø§Øª ØºÙŠØ± Ù…ØªÙˆØ§Ø²Ù†Ø© (Ø£Ø¹Ø¯Ø§Ø¯ Ù…Ø®ØªÙ„ÙØ©)\")\n",
    "    print(\"   ğŸ’¡ Imbalanced categories might need special handling in ML models\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Check for Duplicates | Ø§Ù„Ø®Ø·ÙˆØ© 5: Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª\n",
    "\n",
    "**BEFORE**: We might have the same row appearing multiple times.\n",
    "\n",
    "**AFTER**: We'll identify duplicate rows that could skew our analysis!\n",
    "\n",
    "**Why check for duplicates?**\n",
    "- Duplicates can bias our models (same data counted twice)\n",
    "- They waste computational resources\n",
    "- They indicate data collection issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "6. Column-specific Statistics\n",
      "Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©\n",
      "============================================================\n",
      "\n",
      "ğŸ’° Price statistics / Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø³Ø¹Ø±:\n",
      "   (Understanding price distribution helps us build better models)\n",
      "   Mean (Average): $457,000.00\n",
      "   Median (Middle): $435,000.00\n",
      "   Standard Deviation (Spread): $160,488.84\n",
      "   Min (Lowest): $250,000.00\n",
      "   Max (Highest): $750,000.00\n",
      "\n",
      "   âœ… Mean and median are close - data looks balanced!\n"
     ]
    }
   ],
   "source": [
    "# Calculate statistics for a specific column (price)\n",
    "# Why focus on price? It's our target variable - we want to predict it!\n",
    "# Understanding its distribution helps us choose the right model\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"6. Column-specific Statistics\")\n",
    "print(\"Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nğŸ’° Price statistics / Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø³Ø¹Ø±:\")\n",
    "print(\"   (Understanding price distribution helps us build better models)\")\n",
    "print(f\"   Mean (Average): ${df_loaded['price'].mean():,.2f}\")\n",
    "print(f\"   Median (Middle): ${df_loaded['price'].median():,.2f}\")\n",
    "print(f\"   Standard Deviation (Spread): ${df_loaded['price'].std():,.2f}\")\n",
    "print(f\"   Min (Lowest): ${df_loaded['price'].min():,.2f}\")\n",
    "print(f\"   Max (Highest): ${df_loaded['price'].max():,.2f}\")\n",
    "\n",
    "# Why median vs mean? Median is less affected by outliers!\n",
    "if abs(df_loaded['price'].mean() - df_loaded['price'].median()) > df_loaded['price'].std():\n",
    "    print(\"\\n   âš ï¸  Mean and median are very different - possible outliers!\")\n",
    "else:\n",
    "    print(\"\\n   âœ… Mean and median are close - data looks balanced!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Categorical Data Analysis | Ø§Ù„Ø®Ø·ÙˆØ© 7: ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙØ¦ÙˆÙŠØ©\n",
    "\n",
    "**BEFORE**: We see categorical values (like 'A', 'B', 'C' for location) but don't know their distribution.\n",
    "\n",
    "**AFTER**: We'll count how many times each category appears to understand the balance!\n",
    "\n",
    "**Why analyze categorical data?**\n",
    "- Shows if categories are balanced or imbalanced\n",
    "- Helps decide if we need encoding (one-hot, label encoding)\n",
    "- Reveals data quality issues (unexpected categories)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Summary: What We Learned | Ø§Ù„Ù…Ù„Ø®Øµ: Ù…Ø§ ØªØ¹Ù„Ù…Ù†Ø§Ù‡\n",
    "\n",
    "**BEFORE this notebook**: We had raw data files we couldn't use.\n",
    "\n",
    "**AFTER this notebook**: We can:\n",
    "- âœ… Load data from CSV files\n",
    "- âœ… Inspect data structure and types\n",
    "- âœ… Calculate statistical summaries\n",
    "- âœ… Identify data quality issues (missing values, duplicates)\n",
    "- âœ… Analyze both numerical and categorical data\n",
    "\n",
    "**Next Steps**: \n",
    "- ğŸ““ Example 2: Data Cleaning (fix the issues we found)\n",
    "- ğŸ““ Example 3: Data Preprocessing (prepare data for modeling)\n",
    "- ğŸ““ Example 4: Linear Regression (build our first model!)\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Example 1 Complete! | Ø§ÙƒØªÙ…Ù„ Ø§Ù„Ù…Ø«Ø§Ù„ 1!\n",
    "\n",
    "You've learned the foundation of data science: **exploration before modeling**!\n",
    "\n",
    "**Key Takeaway**: Always explore your data first. You can't build good models on bad data!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
