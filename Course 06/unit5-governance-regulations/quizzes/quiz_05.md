# Quiz 5: Governance and Regulations
## اختبار 5: الحوكمة واللوائح

**Time Limit:** 30 minutes | **Marks:** 30 points

---

## Part 1: Multiple Choice (10 points)

### Question 1 (2 points)
What is AI governance?
- A) Making AI faster
- B) Framework of policies, processes, and controls for responsible AI development and deployment
- C) Making AI cheaper
- D) Training AI models

---

### Question 2 (2 points)
What is the EU AI Act?
- A) A law requiring all AI to be public
- A) A comprehensive regulation for AI systems in the European Union
- C) A guideline for AI research
- D) A standard for AI hardware

---

### Question 3 (2 points)
What are high-risk AI systems?
- A) All AI systems
- B) AI systems that could cause harm to health, safety, or fundamental rights
- C) Only medical AI
- D) Only autonomous vehicles

---

### Question 4 (2 points)
What is an AI ethics board?
- A) A group that trains AI models
- B) A committee that oversees ethical AI development and deployment
- C) A group that tests AI models
- D) A regulatory body

---

### Question 5 (2 points)
What is the purpose of algorithmic impact assessments?
- A) To measure model accuracy
- B) To evaluate potential impacts of AI systems before deployment
- C) To test model speed
- D) To calculate costs

---

## Part 2: Short Answer (10 points)

### Question 6 (5 points)
Explain the key principles of the EU AI Act and how they apply to different risk categories.

**EU AI Act Key Principles:**

1. **Risk-Based Approach:**
   - Systems categorized by risk level
   - Higher risk = stricter requirements
   - Categories: Prohibited, High-Risk, Limited Risk, Minimal Risk

2. **Prohibited AI Practices:**
   - Social scoring by governments
   - Real-time remote biometric identification (with exceptions)
   - Exploitation of vulnerabilities
   - Subliminal manipulation
   - Example: Mass surveillance systems

3. **High-Risk AI Systems:**
   - Systems that could harm health, safety, or fundamental rights
   - Requirements: Risk management, data governance, transparency, human oversight, accuracy
   - Examples: Medical devices, hiring systems, credit scoring
   - Must undergo conformity assessment

4. **Limited Risk AI:**
   - Transparency obligations
   - Users must know they're interacting with AI
   - Example: Chatbots, deepfakes

5. **Minimal Risk AI:**
   - No specific obligations
   - Voluntary codes of conduct
   - Example: Spam filters, recommendation systems

**Application:**
- **Healthcare AI:** High-risk, requires extensive documentation, human oversight
- **Entertainment AI:** Minimal risk, fewer requirements
- **Hiring AI:** High-risk, must ensure fairness, transparency
- **Social Media AI:** Limited risk, transparency required

---

### Question 7 (5 points)
What are the main components of an effective AI governance framework?

**Key Components:**

1. **Policies and Standards:**
   - Clear AI ethics policies
   - Technical standards and guidelines
   - Code of conduct for developers
   - Example: Responsible AI principles, development guidelines

2. **Organizational Structure:**
   - AI ethics board or committee
   - Responsible AI officer/team
   - Clear roles and responsibilities
   - Example: Cross-functional ethics committee

3. **Risk Management:**
   - Risk assessment processes
   - Algorithmic impact assessments
   - Regular audits and reviews
   - Example: Pre-deployment risk analysis

4. **Compliance:**
   - Regulatory compliance (GDPR, AI Act, etc.)
   - Industry-specific regulations
   - Legal review processes
   - Example: Healthcare AI compliance with HIPAA

5. **Transparency and Documentation:**
   - Model documentation (model cards)
   - Data documentation (data sheets)
   - Decision logs and audit trails
   - Example: Comprehensive model documentation

6. **Human Oversight:**
   - Human-in-the-loop for critical decisions
   - Review and approval processes
   - Escalation procedures
   - Example: Medical diagnosis review

7. **Monitoring and Evaluation:**
   - Continuous performance monitoring
   - Bias and fairness monitoring
   - Regular model evaluations
   - Example: Automated monitoring dashboards

8. **Training and Education:**
   - AI ethics training for developers
   - User education
   - Awareness programs
   - Example: Regular ethics workshops

9. **Incident Response:**
   - Procedures for handling AI failures
   - Reporting mechanisms
   - Remediation processes
   - Example: Incident response plan

10. **Stakeholder Engagement:**
    - Input from affected communities
    - Public consultation
    - Multi-stakeholder governance
    - Example: Community advisory boards

---

## Part 3: Case Analysis (10 points)

### Question 8 (5 points)
A company wants to deploy an AI system for automated hiring. What governance measures should they implement?

**Governance Measures:**

1. **Pre-Deployment:**
   - **Risk Assessment:** Evaluate potential impacts on candidates
   - **Algorithmic Impact Assessment:** Document system design, data, risks
   - **Fairness Audit:** Test for bias across protected groups
   - **Legal Review:** Ensure compliance with employment laws
   - **Ethics Review:** AI ethics board approval

2. **Technical Measures:**
   - **Fairness Constraints:** Implement demographic parity or equalized odds
   - **Explainability:** Use XAI to explain hiring decisions
   - **Transparency:** Document model, data, and decision criteria
   - **Validation:** Extensive testing before deployment

3. **Organizational:**
   - **AI Ethics Board:** Oversight committee
   - **Responsible AI Officer:** Designated person accountable
   - **Training:** Educate HR team on AI system
   - **Policies:** Clear policies on AI use in hiring

4. **Operational:**
   - **Human Oversight:** Human review for final decisions
   - **Appeal Process:** Mechanism for candidates to challenge decisions
   - **Monitoring:** Track hiring rates, accuracy, bias metrics
   - **Documentation:** Log all hiring decisions

5. **Compliance:**
   - **Employment Laws:** Comply with anti-discrimination laws
   - **GDPR:** If in EU, ensure data protection compliance
   - **Industry Standards:** Follow best practices
   - **Regular Audits:** Periodic compliance reviews

6. **Transparency:**
   - **Candidate Communication:** Inform candidates about AI use
   - **Explainable Decisions:** Provide reasons for decisions
   - **Public Disclosure:** Algorithmic impact assessment available

---

### Question 9 (5 points)
What are the main challenges in implementing AI governance? How can organizations address them?

**Main Challenges:**

1. **Regulatory Complexity:**
   - Multiple, sometimes conflicting regulations
   - Rapidly evolving legal landscape
   - **Solution:** Legal expertise, compliance teams, regular updates

2. **Technical Challenges:**
   - Implementing fairness, explainability, privacy
   - Balancing competing objectives
   - **Solution:** Better tools, technical expertise, research

3. **Organizational Resistance:**
   - Perceived as slowing innovation
   - Additional costs and complexity
   - **Solution:** Leadership buy-in, demonstrate value, integrate into workflow

4. **Resource Constraints:**
   - Requires expertise, time, money
   - Small organizations may struggle
   - **Solution:** Prioritize high-risk systems, use frameworks, external support

5. **Measurement Difficulties:**
   - Hard to measure fairness, explainability
   - Unclear success metrics
   - **Solution:** Define clear metrics, use standardized frameworks

6. **Cultural Change:**
   - Requires shift in mindset
   - Developers may resist constraints
   - **Solution:** Training, incentives, cultural change programs

7. **Rapid Technology Change:**
   - AI evolves quickly
   - Governance may lag behind
   - **Solution:** Flexible frameworks, regular updates, adaptive governance

**Addressing Strategies:**
- **Start Small:** Begin with high-risk systems
- **Use Frameworks:** Adopt existing governance frameworks
- **Build Expertise:** Train or hire AI ethics experts
- **Integrate Early:** Build governance into development process
- **Stakeholder Engagement:** Involve all relevant parties
- **Continuous Improvement:** Regular review and updates
- **Industry Collaboration:** Learn from others, share best practices

---

## Answer Key

**Part 1:**
1. B) Framework of policies, processes, and controls for responsible AI development and deployment
2. B) A comprehensive regulation for AI systems in the European Union
3. B) AI systems that could cause harm to health, safety, or fundamental rights
4. B) A committee that oversees ethical AI development and deployment
5. B) To evaluate potential impacts of AI systems before deployment

**Part 2:**
6. Key principles with risk categories explained - 5 points
7. Main components of governance framework - 5 points

**Part 3:**
8. Comprehensive governance measures - 5 points
9. Challenges and solutions - 5 points

**Total: 30 points**

---

## Grading Rubric

- **90-100% (27-30 points):** Excellent understanding
- **80-89% (24-26 points):** Good understanding
- **70-79% (21-23 points):** Satisfactory
- **60-69% (18-20 points):** Needs improvement
- **Below 60% (<18 points):** Requires additional study
