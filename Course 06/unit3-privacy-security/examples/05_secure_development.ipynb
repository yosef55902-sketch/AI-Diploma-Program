{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 3: Privacy, Security, and Data Protection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Unit 3 - Example 5: Secure AI Development Practices\n",
      "================================================================================\n",
      "\n",
      "1. Security Vulnerabilities in AI Systems:\n",
      "\n",
      "Adversarial Attacks:\n",
      "  Severity: High\n",
      "  Impact: 9\n",
      "  Likelihood: 7\n",
      "  Description: Malicious inputs designed to fool AI models\n",
      "\n",
      "Model Inversion:\n",
      "  Severity: High\n",
      "  Impact: 8\n",
      "  Likelihood: 6\n",
      "  Description: Reconstructing training data from model outputs\n",
      "\n",
      "Membership Inference:\n",
      "  Severity: Medium\n",
      "  Impact: 7\n",
      "  Likelihood: 7\n",
      "  Description: Determining if specific data was in training set\n",
      "\n",
      "Data Poisoning:\n",
      "  Severity: High\n",
      "  Impact: 9\n",
      "  Likelihood: 5\n",
      "  Description: Injecting malicious data into training set\n",
      "\n",
      "Model Theft:\n",
      "  Severity: Medium\n",
      "  Impact: 6\n",
      "  Likelihood: 6\n",
      "  Description: Stealing model architecture and parameters\n",
      "\n",
      "Insufficient Access Controls:\n",
      "  Severity: High\n",
      "  Impact: 8\n",
      "  Likelihood: 8\n",
      "  Description: Unauthorized access to models or data\n",
      "\n",
      "================================================================================\n",
      "2. Secure Development Practices:\n",
      "================================================================================\n",
      "\n",
      "Input Validation (Development):\n",
      "  Importance: 10\n",
      "  Implementation: Validate and sanitize all inputs\n",
      "\n",
      "Output Sanitization (Development):\n",
      "  Importance: 9\n",
      "  Implementation: Sanitize model outputs before use\n",
      "\n",
      "Access Control (Deployment):\n",
      "  Importance: 10\n",
      "  Implementation: Implement role-based access control\n",
      "\n",
      "Encryption (All Phases):\n",
      "  Importance: 10\n",
      "  Implementation: Encrypt data at rest and in transit\n",
      "\n",
      "Security Testing (Testing):\n",
      "  Importance: 9\n",
      "  Implementation: Regular security audits and penetration testing\n",
      "\n",
      "Monitoring (Operations):\n",
      "  Importance: 9\n",
      "  Implementation: Monitor for anomalies and attacks\n",
      "\n",
      "Incident Response (Operations):\n",
      "  Importance: 8\n",
      "  Implementation: Have response plan for security incidents\n",
      "\n",
      "================================================================================\n",
      "3. Security Risk Matrix:\n",
      "================================================================================\n",
      "\n",
      "Insufficient Access Controls:\n",
      "  Risk Score: 64\n",
      "  Impact: 8, Likelihood: 8\n",
      "\n",
      "Adversarial Attacks:\n",
      "  Risk Score: 63\n",
      "  Impact: 9, Likelihood: 7\n",
      "\n",
      "Membership Inference:\n",
      "  Risk Score: 49\n",
      "  Impact: 7, Likelihood: 7\n",
      "\n",
      "Model Inversion:\n",
      "  Risk Score: 48\n",
      "  Impact: 8, Likelihood: 6\n",
      "\n",
      "Data Poisoning:\n",
      "  Risk Score: 45\n",
      "  Impact: 9, Likelihood: 5\n",
      "\n",
      "Model Theft:\n",
      "  Risk Score: 36\n",
      "  Impact: 6, Likelihood: 6\n",
      "\n",
      "================================================================================\n",
      "Creating Visualizations...\n",
      "================================================================================\n",
      "✅ Saved: security_vulnerabilities.png\n",
      "✅ Saved: secure_practices.png\n",
      "\n",
      "================================================================================\n",
      "SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Key Takeaways:\n",
      "1. AI systems face unique security vulnerabilities\n",
      "2. Secure development practices should be applied throughout the lifecycle\n",
      "3. Risk assessment helps prioritize security measures\n",
      "4. Security testing and monitoring are essential\n",
      "5. Incident response plans should be prepared in advance\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Unit 3: Privacy, Security, and Data Protection\n",
    "Example 5: Secure AI Development Practices\n",
    "This example demonstrates secure AI development practices:\n",
    "- Security vulnerabilities in AI systems\n",
    "- Secure coding practices\n",
    "- Security testing\n",
    "- Incident response\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "sns.set_style(\"whitegrid\")\n",
    "# ============================================================================\n",
    "# SECURITY VULNERABILITIES\n",
    "# ============================================================================\n",
    "def identify_security_vulnerabilities():\n",
    "    \"\"\"\n",
    "    Identify common security vulnerabilities in AI systems\n",
    "    \"\"\"\n",
    "    vulnerabilities = {\n",
    "        'Adversarial Attacks': {\n",
    "            'severity': 'High',\n",
    "            'impact': 9,\n",
    "            'likelihood': 7,\n",
    "            'description': 'Malicious inputs designed to fool AI models'\n",
    "        },\n",
    "        'Model Inversion': {\n",
    "            'severity': 'High',\n",
    "            'impact': 8,\n",
    "            'likelihood': 6,\n",
    "            'description': 'Reconstructing training data from model outputs'\n",
    "        },\n",
    "        'Membership Inference': {\n",
    "            'severity': 'Medium',\n",
    "            'impact': 7,\n",
    "            'likelihood': 7,\n",
    "            'description': 'Determining if specific data was in training set'\n",
    "        },\n",
    "        'Data Poisoning': {\n",
    "            'severity': 'High',\n",
    "            'impact': 9,\n",
    "            'likelihood': 5,\n",
    "            'description': 'Injecting malicious data into training set'\n",
    "        },\n",
    "        'Model Theft': {\n",
    "            'severity': 'Medium',\n",
    "            'impact': 6,\n",
    "            'likelihood': 6,\n",
    "            'description': 'Stealing model architecture and parameters'\n",
    "        },\n",
    "        'Insufficient Access Controls': {\n",
    "            'severity': 'High',\n",
    "            'impact': 8,\n",
    "            'likelihood': 8,\n",
    "            'description': 'Unauthorized access to models or data'\n",
    "        }\n",
    "    }\n",
    "    return vulnerabilities\n",
    "# ============================================================================\n",
    "# SECURE DEVELOPMENT PRACTICES\n",
    "# ============================================================================\n",
    "def secure_development_practices():\n",
    "    \"\"\"\n",
    "    Define secure AI development practices\n",
    "    \"\"\"\n",
    "    practices = {\n",
    "        'Input Validation': {\n",
    "            'phase': 'Development',\n",
    "            'importance': 10,\n",
    "            'implementation': 'Validate and sanitize all inputs'\n",
    "        },\n",
    "        'Output Sanitization': {\n",
    "            'phase': 'Development',\n",
    "            'importance': 9,\n",
    "            'implementation': 'Sanitize model outputs before use'\n",
    "        },\n",
    "        'Access Control': {\n",
    "            'phase': 'Deployment',\n",
    "            'importance': 10,\n",
    "            'implementation': 'Implement role-based access control'\n",
    "        },\n",
    "        'Encryption': {\n",
    "            'phase': 'All Phases',\n",
    "            'importance': 10,\n",
    "            'implementation': 'Encrypt data at rest and in transit'\n",
    "        },\n",
    "        'Security Testing': {\n",
    "            'phase': 'Testing',\n",
    "            'importance': 9,\n",
    "            'implementation': 'Regular security audits and penetration testing'\n",
    "        },\n",
    "        'Monitoring': {\n",
    "            'phase': 'Operations',\n",
    "            'importance': 9,\n",
    "            'implementation': 'Monitor for anomalies and attacks'\n",
    "        },\n",
    "        'Incident Response': {\n",
    "            'phase': 'Operations',\n",
    "            'importance': 8,\n",
    "            'implementation': 'Have response plan for security incidents'\n",
    "        }\n",
    "    }\n",
    "    return practices\n",
    "# ============================================================================\n",
    "# SECURITY RISK MATRIX\n",
    "# ============================================================================\n",
    "def create_risk_matrix(vulnerabilities):\n",
    "    \"\"\"\n",
    "    Create risk matrix for security vulnerabilities\n",
    "    \"\"\"\n",
    "    risk_matrix = []\n",
    "    for vuln, info in vulnerabilities.items():\n",
    "        risk_score = info['impact'] * info['likelihood']\n",
    "        risk_matrix.append({\n",
    "            'vulnerability': vuln,\n",
    "            'impact': info['impact'],\n",
    "            'likelihood': info['likelihood'],\n",
    "            'risk_score': risk_score,\n",
    "            'severity': info['severity']\n",
    "        })\n",
    "    return risk_matrix\n",
    "# ============================================================================\n",
    "# VISUALIZATIONS\n",
    "# ============================================================================\n",
    "def plot_security_vulnerabilities(vulnerabilities):\n",
    "    \"\"\"\n",
    "    Plot security vulnerabilities analysis\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    vuln_names = list(vulnerabilities.keys())\n",
    "    impacts = [v['impact'] for v in vulnerabilities.values()]\n",
    "    likelihoods = [v['likelihood'] for v in vulnerabilities.values()]\n",
    "    # Risk matrix\n",
    "    scatter = axes[0].scatter(likelihoods, impacts, s=300, alpha=0.7, \n",
    "                             c=impacts, cmap='RdYlGn_r', edgecolors='black', linewidth=2)\n",
    "    for i, name in enumerate(vuln_names):\n",
    "        axes[0].annotate(name, (likelihoods[i], impacts[i]), \n",
    "                        xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "    axes[0].set_xlabel('Likelihood (1-10)', fontsize=11, fontweight='bold')\n",
    "    axes[0].set_ylabel('Impact (1-10)', fontsize=11, fontweight='bold')\n",
    "    axes[0].set_title('Security Risk Matrix', fontsize=12, fontweight='bold')\n",
    "    axes[0].grid(alpha=0.3)\n",
    "    axes[0].set_xlim([0, 11])\n",
    "    axes[0].set_ylim([0, 11])\n",
    "    plt.colorbar(scatter, ax=axes[0], label='Impact')\n",
    "    # Severity distribution\n",
    "    severity_counts = {}\n",
    "    for v in vulnerabilities.values():\n",
    "        sev = v['severity']\n",
    "        severity_counts[sev] = severity_counts.get(sev, 0) + 1\n",
    "    colors = {'High': '#e74c3c', 'Medium': '#f39c12', 'Low': '#2ecc71'}\n",
    "    axes[1].bar(severity_counts.keys(), severity_counts.values(), \n",
    "               color=[colors[s] for s in severity_counts.keys()], alpha=0.8)\n",
    "    axes[1].set_title('Vulnerability Severity Distribution', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_ylabel('Count')\n",
    "    axes[1].grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('unit3-privacy-security', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    print(\"✅ Saved: security_vulnerabilities.png\")\n",
    "    plt.close()\n",
    "def plot_secure_practices(practices):\n",
    "    \"\"\"\n",
    "    Plot secure development practices by phase\n",
    "    \"\"\"\n",
    "    phases = {}\n",
    "    for practice, info in practices.items():\n",
    "        phase = info['phase']\n",
    "        if phase not in phases:\n",
    "            phases[phase] = []\n",
    "        phases[phase].append((practice, info['importance']))\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    y_pos = 0\n",
    "    colors = ['#3498db', '#2ecc71', '#f39c12', '#9b59b6']\n",
    "    color_idx = 0\n",
    "    for phase, items in phases.items():\n",
    "        practices_list = [item[0] for item in items]\n",
    "        importance_list = [item[1] for item in items]\n",
    "        x_start = y_pos\n",
    "        for i, (practice, importance) in enumerate(items):\n",
    "            ax.barh(y_pos, importance, left=0, color=colors[color_idx % len(colors)], \n",
    "                   alpha=0.7, edgecolor='black')\n",
    "            ax.text(importance/2, y_pos, practice, ha='center', va='center', \n",
    "                   fontsize=9, fontweight='bold')\n",
    "            y_pos += 1\n",
    "        # Add phase label\n",
    "        ax.text(-0.5, (x_start + y_pos - 1) / 2, phase, ha='right', va='center',\n",
    "               fontsize=10, fontweight='bold', rotation=0)\n",
    "        y_pos += 0.5\n",
    "        color_idx += 1\n",
    "    ax.set_xlabel('Importance (1-10)', fontsize=11, fontweight='bold')\n",
    "    ax.set_title('Secure Development Practices by Phase', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlim([0, 11])\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    ax.set_yticks([])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('unit3-privacy-security', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    print(\"✅ Saved: secure_practices.png\")\n",
    "    plt.close()\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\"*80)\n",
    "    print(\"Unit 3 - Example 5: Secure AI Development Practices\")\n",
    "    print(\"=\"*80)\n",
    "    # Security Vulnerabilities\n",
    "    print(\"\\n1. Security Vulnerabilities in AI Systems:\")\n",
    "    vulnerabilities = identify_security_vulnerabilities()\n",
    "    for vuln, info in vulnerabilities.items():\n",
    "        print(f\"\\n{vuln}:\")\n",
    "        print(f\"  Severity: {info['severity']}\")\n",
    "        print(f\"  Impact: {info['impact']}\")\n",
    "        print(f\"  Likelihood: {info['likelihood']}\")\n",
    "        print(f\"  Description: {info['description']}\")\n",
    "    # Secure Practices\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"2. Secure Development Practices:\")\n",
    "    print(\"=\"*80)\n",
    "    practices = secure_development_practices()\n",
    "    for practice, info in practices.items():\n",
    "        print(f\"\\n{practice} ({info['phase']}):\")\n",
    "        print(f\"  Importance: {info['importance']}\")\n",
    "        print(f\"  Implementation: {info['implementation']}\")\n",
    "    # Risk Matrix\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"3. Security Risk Matrix:\")\n",
    "    print(\"=\"*80)\n",
    "    risk_matrix = create_risk_matrix(vulnerabilities)\n",
    "    for risk in sorted(risk_matrix, key=lambda x: x['risk_score'], reverse=True):\n",
    "        print(f\"\\n{risk['vulnerability']}:\")\n",
    "        print(f\"  Risk Score: {risk['risk_score']}\")\n",
    "        print(f\"  Impact: {risk['impact']}, Likelihood: {risk['likelihood']}\")\n",
    "    # Create visualizations\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Creating Visualizations...\")\n",
    "    print(\"=\"*80)\n",
    "    plot_security_vulnerabilities(vulnerabilities)\n",
    "    plot_secure_practices(practices)\n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nKey Takeaways:\")\n",
    "    print(\"1. AI systems face unique security vulnerabilities\")\n",
    "    print(\"2. Secure development practices should be applied throughout the lifecycle\")\n",
    "    print(\"3. Risk assessment helps prioritize security measures\")\n",
    "    print(\"4. Security testing and monitoring are essential\")\n",
    "    print(\"5. Incident response plans should be prepared in advance\")\n",
    "    print(\"=\"*80 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
