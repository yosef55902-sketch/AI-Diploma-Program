{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 3: Privacy, Security, and Data Protection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Unit 3 - Example 3: Differential Privacy\n",
      "================================================================================\n",
      "\n",
      "Dataset: 1000 samples\n",
      "True mean: $50,289.98\n",
      "True count: 1000\n",
      "\n",
      "================================================================================\n",
      "Differential Privacy Demonstration\n",
      "================================================================================\n",
      "\n",
      "Epsilon (ε) = 0.1:\n",
      "  True mean: $50,289.98, Noisy mean: $49,126.14\n",
      "  Error: $1,163.84\n",
      "  True count: 1000, Noisy count: 984\n",
      "  Privacy level: 10.00 (higher = more private)\n",
      "\n",
      "Epsilon (ε) = 0.5:\n",
      "  True mean: $50,289.98, Noisy mean: $50,357.79\n",
      "  Error: $67.81\n",
      "  True count: 1000, Noisy count: 1001\n",
      "  Privacy level: 2.00 (higher = more private)\n",
      "\n",
      "Epsilon (ε) = 1.0:\n",
      "  True mean: $50,289.98, Noisy mean: $49,996.09\n",
      "  Error: $293.89\n",
      "  True count: 1000, Noisy count: 1002\n",
      "  Privacy level: 1.00 (higher = more private)\n",
      "\n",
      "Epsilon (ε) = 2.0:\n",
      "  True mean: $50,289.98, Noisy mean: $50,169.53\n",
      "  Error: $120.45\n",
      "  True count: 1000, Noisy count: 1000\n",
      "  Privacy level: 0.50 (higher = more private)\n",
      "\n",
      "Epsilon (ε) = 5.0:\n",
      "  True mean: $50,289.98, Noisy mean: $50,301.50\n",
      "  Error: $11.52\n",
      "  True count: 1000, Noisy count: 1000\n",
      "  Privacy level: 0.20 (higher = more private)\n",
      "\n",
      "================================================================================\n",
      "Creating Visualizations...\n",
      "================================================================================\n",
      "✅ Saved: differential_privacy_analysis.png\n",
      "\n",
      "================================================================================\n",
      "SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Key Takeaways:\n",
      "1. Differential privacy adds controlled noise to protect individual privacy\n",
      "2. Epsilon (ε) controls privacy level: smaller ε = more private\n",
      "3. There is a trade-off between privacy and data utility\n",
      "4. Differential privacy provides mathematical privacy guarantees\n",
      "5. Choose epsilon based on privacy requirements and acceptable error\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Unit 3: Privacy, Security, and Data Protection\n",
    "Example 3: Differential Privacy\n",
    "This example demonstrates differential privacy concepts:\n",
    "- Adding noise for privacy\n",
    "- Privacy-utility trade-offs\n",
    "- Epsilon (ε) parameter\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "sns.set_style(\"whitegrid\")\n",
    "# ============================================================================\n",
    "# DIFFERENTIAL PRIVACY IMPLEMENTATION\n",
    "# ============================================================================\n",
    "def add_laplace_noise(value, epsilon=1.0, sensitivity=1.0):\n",
    "    \"\"\"\n",
    "    Add Laplace noise for differential privacy\n",
    "    epsilon (ε): privacy parameter (smaller = more private)\n",
    "    sensitivity: maximum change in output from changing one record\n",
    "    \"\"\"\n",
    "    scale = sensitivity / epsilon\n",
    "    noise = np.random.laplace(0, scale)\n",
    "    return value + noise\n",
    "def differentially_private_mean(data, epsilon=1.0):\n",
    "    \"\"\"\n",
    "    Compute differentially private mean\n",
    "    \"\"\"\n",
    "    true_mean = np.mean(data)\n",
    "    sensitivity = (data.max() - data.min()) / len(data)\n",
    "    noisy_mean = add_laplace_noise(true_mean, epsilon, sensitivity)\n",
    "    return true_mean, noisy_mean\n",
    "def differentially_private_count(data, epsilon=1.0):\n",
    "    \"\"\"\n",
    "    Compute differentially private count\n",
    "    \"\"\"\n",
    "    true_count = len(data)\n",
    "    sensitivity = 1.0  # Adding\n",
    "    noisy_count = add_laplace_noise(true_count, epsilon, sensitivity)\n",
    "    return true_count, max(0, int(noisy_count))  # Ensure non-negative\n",
    "# ============================================================================\n",
    "# PRIVACY-UTILITY TRADE-OFF\n",
    "# ============================================================================\n",
    "def analyze_epsilon_impact(data, epsilon_values):\n",
    "    \"\"\"\n",
    "    Analyze how different epsilon values affect privacy and utility\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    true_mean = np.mean(data)\n",
    "    true_count = len(data)\n",
    "    for epsilon in epsilon_values:\n",
    "        # Compute multiple times to show variance\n",
    "        noisy_means = []\n",
    "        noisy_counts = []\n",
    "        for _ in range(10):\n",
    "            _, noisy_mean = differentially_private_mean(data, epsilon)\n",
    "            _, noisy_count = differentially_private_count(data, epsilon)\n",
    "            noisy_means.append(noisy_mean)\n",
    "            noisy_counts.append(noisy_count)\n",
    "        mean_error = np.mean([abs(m - true_mean) for m in noisy_means])\n",
    "        count_error = np.mean([abs(c - true_count) for c in noisy_counts])\n",
    "        results.append({\n",
    "            'epsilon': epsilon,\n",
    "            'privacy_level': 1.0 / epsilon,  # Higher epsilon = less private\n",
    "            'mean_error': mean_error,\n",
    "            'count_error': count_error,\n",
    "            'noisy_mean_avg': np.mean(noisy_means),\n",
    "            'noisy_count_avg': np.mean(noisy_counts)\n",
    "        })\n",
    "    return results\n",
    "# ============================================================================\n",
    "# VISUALIZATIONS\n",
    "# ============================================================================\n",
    "def plot_differential_privacy_comparison(data, epsilon_values):\n",
    "    \"\"\"\n",
    "    Plot comparison of differential privacy with different epsilon values\n",
    "    \"\"\"\n",
    "    results = analyze_epsilon_impact(data, epsilon_values)\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    epsilons = [r['epsilon'] for r in results]\n",
    "    mean_errors = [r['mean_error'] for r in results]\n",
    "    count_errors = [r['count_error'] for r in results]\n",
    "    privacy_levels = [r['privacy_level'] for r in results]\n",
    "    # Mean error vs epsilon\n",
    "    axes[0, 0].plot(epsilons, mean_errors, marker='o', linewidth=2, markersize=8, color='#e74c3c')\n",
    "    axes[0, 0].set_xlabel('Epsilon (ε)', fontsize=11, fontweight='bold')\n",
    "    axes[0, 0].set_ylabel('Mean Error', fontsize=11, fontweight='bold')\n",
    "    axes[0, 0].set_title('Privacy vs Accuracy: Mean Estimation', fontsize=12, fontweight='bold')\n",
    "    axes[0, 0].grid(alpha=0.3)\n",
    "    axes[0, 0].set_xscale('log')\n",
    "    # Count error vs epsilon\n",
    "    axes[0, 1].plot(epsilons, count_errors, marker='s', linewidth=2, markersize=8, color='#3498db')\n",
    "    axes[0, 1].set_xlabel('Epsilon (ε)', fontsize=11, fontweight='bold')\n",
    "    axes[0, 1].set_ylabel('Count Error', fontsize=11, fontweight='bold')\n",
    "    axes[0, 1].set_title('Privacy vs Accuracy: Count Estimation', fontsize=12, fontweight='bold')\n",
    "    axes[0, 1].grid(alpha=0.3)\n",
    "    axes[0, 1].set_xscale('log')\n",
    "    # Privacy level\n",
    "    axes[1, 0].bar(range(len(epsilons)), privacy_levels, color='#9b59b6', alpha=0.8)\n",
    "    axes[1, 0].set_xlabel('Epsilon Value Index', fontsize=11, fontweight='bold')\n",
    "    axes[1, 0].set_ylabel('Privacy Level (Higher is Better)', fontsize=11, fontweight='bold')\n",
    "    axes[1, 0].set_title('Privacy Level by Epsilon', fontsize=12, fontweight='bold')\n",
    "    axes[1, 0].set_xticks(range(len(epsilons)))\n",
    "    axes[1, 0].set_xticklabels([f'ε={e:.2f}' for e in epsilons], rotation=15)\n",
    "    axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "    # Privacy-utility trade-off\n",
    "    axes[1, 1].scatter(privacy_levels, mean_errors, s=200, alpha=0.7, \n",
    "                      c=epsilons, cmap='RdYlGn_r', edgecolors='black', linewidth=2)\n",
    "    axes[1, 1].set_xlabel('Privacy Level', fontsize=11, fontweight='bold')\n",
    "    axes[1, 1].set_ylabel('Mean Error (Lower is Better)', fontsize=11, fontweight='bold')\n",
    "    axes[1, 1].set_title('Privacy-Utility Trade-off', fontsize=12, fontweight='bold')\n",
    "    axes[1, 1].grid(alpha=0.3)\n",
    "    cbar = plt.colorbar(axes[1, 1].collections[0], ax=axes[1, 1])\n",
    "    cbar.set_label('Epsilon (ε)', fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('unit3-privacy-security', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    print(\"✅ Saved: differential_privacy_analysis.png\")\n",
    "    plt.close()\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\"*80)\n",
    "    print(\"Unit 3 - Example 3: Differential Privacy\")\n",
    "    print(\"=\"*80)\n",
    "    # Generate sample data\n",
    "    np.random.seed(42)\n",
    "    data = np.random.normal(50000, 15000, 1000)  # Salary data\n",
    "    print(f\"\\nDataset: {len(data)} samples\")\n",
    "    print(f\"True mean: ${np.mean(data):,.2f}\")\n",
    "    print(f\"True count: {len(data)}\")\n",
    "    # Demonstrate differential privacy\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Differential Privacy Demonstration\")\n",
    "    print(\"=\"*80)\n",
    "    epsilon_values = [0.1, 0.5, 1.0, 2.0, 5.0]\n",
    "    for epsilon in epsilon_values:\n",
    "        true_mean, noisy_mean = differentially_private_mean(data, epsilon)\n",
    "        true_count, noisy_count = differentially_private_count(data, epsilon)\n",
    "        print(f\"\\nEpsilon (ε) = {epsilon}:\")\n",
    "        print(f\"  True mean: ${true_mean:,.2f}, Noisy mean: ${noisy_mean:,.2f}\")\n",
    "        print(f\"  Error: ${abs(noisy_mean - true_mean):,.2f}\")\n",
    "        print(f\"  True count: {true_count}, Noisy count: {noisy_count}\")\n",
    "        print(f\"  Privacy level: {1.0 / epsilon:.2f} (higher = more private)\")\n",
    "    # Create visualizations\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Creating Visualizations...\")\n",
    "    print(\"=\"*80)\n",
    "    plot_differential_privacy_comparison(data, epsilon_values)\n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nKey Takeaways:\")\n",
    "    print(\"1. Differential privacy adds controlled noise to protect individual privacy\")\n",
    "    print(\"2. Epsilon (ε) controls privacy level: smaller ε = more private\")\n",
    "    print(\"3. There is a trade-off between privacy and data utility\")\n",
    "    print(\"4. Differential privacy provides mathematical privacy guarantees\")\n",
    "    print(\"5. Choose epsilon based on privacy requirements and acceptable error\")\n",
    "    print(\"=\"*80 + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
