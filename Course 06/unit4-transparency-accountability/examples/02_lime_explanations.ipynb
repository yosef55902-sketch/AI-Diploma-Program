{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Unit 4: Interpretability, Transparency, and Accountability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: LIME library not available. Using simplified LIME implementation.\n",
            "================================================================================\n",
            "Unit 4 - Example 2: LIME Explanations\n",
            "================================================================================\n",
            "\n",
            "Generating dataset...\n",
            "Dataset shape: (1000, 5)\n",
            "\n",
            "Training Random Forest model...\n",
            "Training Accuracy: 1.0000\n",
            "Test Accuracy: 0.9167\n",
            "\n",
            "Generating LIME explanations...\n",
            "Generated 10 LIME explanations\n",
            "\n",
            "================================================================================\n",
            "Creating Visualizations...\n",
            "================================================================================\n",
            "✅ Saved: lime_explanation.png\n",
            "✅ Saved: lime_comparison.png\n",
            "\n",
            "================================================================================\n",
            "SUMMARY\n",
            "================================================================================\n",
            "\n",
            "Key Takeaways:\n",
            "1. LIME provides local, interpretable explanations\n",
            "2. LIME approximates complex models with simple linear models locally\n",
            "3. LIME works for any black-box model\n",
            "4. LIME explanations are instance-specific\n",
            "5. LIME helps understand individual predictions\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Unit 4: Interpretability, Transparency, and Accountability\n",
        "Example 2: LIME Explanations\n",
        "This example demonstrates LIME (Local Interpretable Model-agnostic Explanations):\n",
        "- LIME for tabular data\n",
        "- LIME for text data (simplified)\n",
        "- Local interpretability\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# Try to import LIME, use simplified version if not available\n",
        "try:\n",
        "    import lime\n",
        "    import lime.lime_tabular\n",
        "    LIME_AVAILABLE = True\n",
        "except ImportError:\n",
        "    LIME_AVAILABLE = False\n",
        "    print(\"Note: LIME library not available. Using simplified LIME implementation.\")\n",
        "plt.rcParams['font.size'] = 10\n",
        "plt.rcParams['figure.figsize'] = (14, 8)\n",
        "sns.set_style(\"whitegrid\")\n",
        "# ============================================================================\n",
        "# SIMPLIFIED LIME IMPLEMENTATION\n",
        "# ============================================================================\n",
        "def lime_explanation_simple(model, X_sample, X_train, feature_names, n_samples=5000):\n",
        "    \"\"\"\n",
        "    Simplified LIME implementation using local linear approximation\n",
        "    \"\"\"\n",
        "    # Generate perturbed samples around the instance\n",
        "    np.random.seed(42)\n",
        "    perturbations = np.random.normal(0, 0.1, (n_samples, X_sample.shape[1]))\n",
        "    X_perturbed = X_sample + perturbations\n",
        "    # Get predictions for perturbed samples\n",
        "    y_perturbed = model.predict_proba(X_perturbed)[:, 1]\n",
        "    # Calculate distances (weights)\n",
        "    distances = np.exp(-np.sum((X_perturbed - X_sample) ** 2, axis=1))\n",
        "    # Fit linear model to approximate local behavior\n",
        "    linear_model = Ridge(alpha=0.1)\n",
        "    linear_model.fit(X_perturbed, y_perturbed, sample_weight=distances)\n",
        "    # Get feature importance (coefficients)\n",
        "    feature_importance = linear_model.coef_\n",
        "    return feature_importance, linear_model\n",
        "# ============================================================================\n",
        "# GENERATE DATASET\n",
        "# ============================================================================\n",
        "def generate_dataset(n_samples=1000):\n",
        "    \"\"\"\n",
        "    Generate synthetic dataset for LIME demonstration\n",
        "    \"\"\"\n",
        "    np.random.seed(42)\n",
        "    # Features\n",
        "    age = np.random.randint(25, 70, n_samples)\n",
        "    income = np.random.normal(60000, 25000, n_samples)\n",
        "    credit_history = np.random.choice([0, 1, 2, 3], n_samples)  # 0=bad, 3=excellent\n",
        "    loan_amount = np.random.uniform(10000, 200000, n_samples)\n",
        "    # Target (loan approval)\n",
        "    approval_prob = (credit_history / 3 * 0.5 +\n",
        "                     (income / 100000) * 0.3 +\n",
        "                     (1 - loan_amount / 200000) * 0.15 +\n",
        "                     (age / 70) * 0.05 +\n",
        "                     np.random.normal(0, 0.05, n_samples))\n",
        "    approval = (approval_prob > 0.5).astype(int)\n",
        "    df = pd.DataFrame({\n",
        "        'age': age,\n",
        "        'income': income,\n",
        "        'credit_history': credit_history,\n",
        "        'loan_amount': loan_amount,\n",
        "        'approved': approval\n",
        "    })\n",
        "    return df\n",
        "# ============================================================================\n",
        "# LIME EXPLANATIONS\n",
        "# ============================================================================\n",
        "def explain_with_lime(model, X_sample, X_train, feature_names, use_library=True):\n",
        "    \"\"\"\n",
        "    Generate LIME explanations for a single instance\n",
        "    \"\"\"\n",
        "    if LIME_AVAILABLE and use_library:\n",
        "        # Use actual LIME library\n",
        "        explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "            X_train, feature_names=feature_names, mode='classification'\n",
        "        )\n",
        "        explanation = explainer.explain_instance(\n",
        "            X_sample[0], model.predict_proba, num_features=len(feature_names)\n",
        "        )\n",
        "        return explanation, explainer\n",
        "    else:\n",
        "        # Use simplified implementation\n",
        "        feature_importance, linear_model = lime_explanation_simple(\n",
        "            model, X_sample, X_train, feature_names\n",
        "        )\n",
        "        return feature_importance, linear_model\n",
        "# ============================================================================\n",
        "# VISUALIZATIONS\n",
        "# ============================================================================\n",
        "def plot_lime_explanation(feature_importance, feature_names, X_sample, sample_idx=0):\n",
        "    \"\"\"\n",
        "    Plot LIME explanation for a single instance\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "    # Sort by absolute importance\n",
        "    indices = np.argsort(np.abs(feature_importance))[::-1]\n",
        "    colors = ['red' if feature_importance[i] < 0 else 'green' for i in indices]\n",
        "    bars = ax.barh(range(len(feature_names)), \n",
        "                   [feature_importance[i] for i in indices],\n",
        "                   color=colors, alpha=0.7)\n",
        "    # Add value labels\n",
        "    for i, (bar, idx) in enumerate(zip(bars, indices)):\n",
        "        height = bar.get_height()\n",
        "        width = bar.get_width()\n",
        "        label = f'{feature_names[idx]}\\n={X_sample[0, idx]:.2f}'\n",
        "        ax.text(width/2 if width > 0 else width/2, i, label,\n",
        "               ha='center' if width > 0 else 'right', va='center', fontsize=9)\n",
        "    ax.set_yticks(range(len(feature_names)))\n",
        "    ax.set_yticklabels([feature_names[i] for i in indices])\n",
        "    ax.set_xlabel('LIME Feature Importance', fontsize=11, fontweight='bold')\n",
        "    ax.set_title(f'LIME Explanation (Sample {sample_idx})', \n",
        "                fontsize=12, fontweight='bold')\n",
        "    ax.axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
        "    ax.grid(axis='x', alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('unit4-transparency-accountability', \n",
        "                dpi=300, bbox_inches='tight')\n",
        "    print(\"✅ Saved: lime_explanation.png\")\n",
        "    plt.close()\n",
        "def plot_lime_comparison(explanations, feature_names, n_samples=5):\n",
        "    \"\"\"\n",
        "    Plot LIME explanations for multiple samples\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(1, n_samples, figsize=(20, 6))\n",
        "    for idx, (importance, X_sample) in enumerate(explanations[:n_samples]):\n",
        "        if idx >= len(axes):\n",
        "            break\n",
        "        # Sort by absolute importance\n",
        "        indices = np.argsort(np.abs(importance))[::-1]\n",
        "        top_k = min(4, len(indices))\n",
        "        top_indices = indices[:top_k]\n",
        "        top_importance = importance[top_indices]\n",
        "        top_names = [feature_names[i] for i in top_indices]\n",
        "        colors = ['red' if imp < 0 else 'green' for imp in top_importance]\n",
        "        axes[idx].barh(range(len(top_names)), top_importance, color=colors, alpha=0.7)\n",
        "        axes[idx].set_yticks(range(len(top_names)))\n",
        "        axes[idx].set_yticklabels(top_names, fontsize=8)\n",
        "        axes[idx].set_title(f'Sample {idx}', fontsize=10, fontweight='bold')\n",
        "        axes[idx].axvline(x=0, color='black', linestyle='--', linewidth=0.5)\n",
        "        axes[idx].grid(axis='x', alpha=0.3)\n",
        "    plt.suptitle('LIME Explanations for Multiple Samples', \n",
        "                fontsize=12, fontweight='bold', y=1.02)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('unit4-transparency-accountability', \n",
        "                dpi=300, bbox_inches='tight')\n",
        "    print(\"✅ Saved: lime_comparison.png\")\n",
        "    plt.close()\n",
        "# ============================================================================\n",
        "# MAIN EXECUTION\n",
        "# ============================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=\"*80)\n",
        "    print(\"Unit 4 - Example 2: LIME Explanations\")\n",
        "    print(\"=\"*80)\n",
        "    # Generate dataset\n",
        "    print(\"\\nGenerating dataset...\")\n",
        "    df = generate_dataset(n_samples=1000)\n",
        "    print(f\"Dataset shape: {df.shape}\")\n",
        "    # Prepare data\n",
        "    feature_names = ['age', 'income', 'credit_history', 'loan_amount']\n",
        "    X = df[feature_names].values\n",
        "    y = df['approved'].values\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.3, random_state=42, stratify=y\n",
        "    )\n",
        "    # Scale features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    # Train model\n",
        "    print(\"\\nTraining Random Forest model...\")\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    train_acc = accuracy_score(y_train, model.predict(X_train_scaled))\n",
        "    test_acc = accuracy_score(y_test, model.predict(X_test_scaled))\n",
        "    print(f\"Training Accuracy: {train_acc:.4f}\")\n",
        "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "    # Generate LIME explanations for multiple samples\n",
        "    print(\"\\nGenerating LIME explanations...\")\n",
        "    explanations = []\n",
        "    for i in range(min(10, len(X_test_scaled))):\n",
        "        X_sample = X_test_scaled[i:i+1]\n",
        "        explanation, _ = explain_with_lime(\n",
        "            model, X_sample, X_train_scaled, feature_names, use_library=LIME_AVAILABLE\n",
        "        )\n",
        "        if isinstance(explanation, np.ndarray):\n",
        "            explanations.append((explanation, X_test[i:i+1]))\n",
        "        else:\n",
        "            # If using LIME library, extract feature importance\n",
        "            exp_list = explanation.as_list()\n",
        "            importance = np.zeros(len(feature_names))\n",
        "            for feature_name, value in exp_list:\n",
        "                idx = feature_names.index(feature_name)\n",
        "                importance[idx] = value\n",
        "            explanations.append((importance, X_test[i:i+1]))\n",
        "    print(f\"Generated {len(explanations)} LIME explanations\")\n",
        "    # Create visualizations\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"Creating Visualizations...\")\n",
        "    print(\"=\"*80)\n",
        "    plot_lime_explanation(explanations[0][0], feature_names, explanations[0][1], sample_idx=0)\n",
        "    plot_lime_comparison(explanations, feature_names, n_samples=5)\n",
        "    # Summary\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"SUMMARY\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"\\nKey Takeaways:\")\n",
        "    print(\"1. LIME provides local, interpretable explanations\")\n",
        "    print(\"2. LIME approximates complex models with simple linear models locally\")\n",
        "    print(\"3. LIME works for any black-box model\")\n",
        "    print(\"4. LIME explanations are instance-specific\")\n",
        "    print(\"5. LIME helps understand individual predictions\")\n",
        "    print(\"=\"*80 + \"\\n\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "course2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
