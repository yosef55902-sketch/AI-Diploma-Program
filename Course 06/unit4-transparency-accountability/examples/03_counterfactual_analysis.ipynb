{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Unit 4: Interpretability, Transparency, and Accountability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "Unit 4 - Example 3: Counterfactual Analysis\n",
            "================================================================================\n",
            "\n",
            "Generating dataset...\n",
            "Dataset shape: (1000, 5)\n",
            "\n",
            "Training Random Forest model...\n",
            "Test Accuracy: 0.9667\n",
            "\n",
            "Original instance (rejected):\n",
            "  Features: {'age': 69.0, 'income': 5029.851084497954, 'credit_score': 639.4051645695864, 'debt_ratio': 0.5370358866525926}\n",
            "  Prediction probability: 0.3900\n",
            "  Prediction: 0\n",
            "\n",
            "Generating counterfactual (to get approved)...\n",
            "Counterfactual found after 1 iterations: Target class reached\n",
            "  Prediction probability: 0.9500\n",
            "  Prediction: 1\n",
            "\n",
            "Performing what-if analysis on credit_score...\n",
            "\n",
            "================================================================================\n",
            "Creating Visualizations...\n",
            "================================================================================\n",
            "✅ Saved: counterfactual_comparison.png\n",
            "✅ Saved: what_if_analysis.png\n",
            "\n",
            "================================================================================\n",
            "SUMMARY\n",
            "================================================================================\n",
            "\n",
            "Key Takeaways:\n",
            "1. Counterfactuals show what needs to change to get a different outcome\n",
            "2. What-if analysis explores how changes in features affect predictions\n",
            "3. Counterfactuals help explain model decisions\n",
            "4. Counterfactuals are useful for actionable insights\n",
            "5. Counterfactual analysis improves model transparency\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Unit 4: Interpretability, Transparency, and Accountability\n",
        "Example 3: Counterfactual Analysis\n",
        "This example demonstrates counterfactual analysis for model interpretability:\n",
        "- Generating counterfactual examples\n",
        "- What-if analysis\n",
        "- Model decision explanations\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.rcParams['font.size'] = 10\n",
        "plt.rcParams['figure.figsize'] = (14, 8)\n",
        "sns.set_style(\"whitegrid\")\n",
        "# ============================================================================\n",
        "# COUNTERFACTUAL GENERATION\n",
        "# ============================================================================\n",
        "def generate_counterfactual(model, X_instance, X_train, feature_names, target_class=1, max_iterations=100):\n",
        "    \"\"\"\n",
        "    Generate counterfactual example by perturbing features\n",
        "    \"\"\"\n",
        "    # Get original prediction\n",
        "    original_pred = model.predict_proba(X_instance)[0, 1]\n",
        "    original_class = model.predict(X_instance)[0]\n",
        "    if original_class == target_class:\n",
        "        return X_instance.copy(), 0, \"Already in target class\"\n",
        "    # Initialize counterfactual\n",
        "    counterfactual = X_instance.copy()\n",
        "    # Feature ranges from training data\n",
        "    feature_ranges = {\n",
        "        i: (X_train[:, i].min(), X_train[:, i].max())\n",
        "        for i in range(X_train.shape[1])\n",
        "    }\n",
        "    # Iteratively modify features\n",
        "    for iteration in range(max_iterations):\n",
        "        # Try modifying each feature\n",
        "        best_change = None\n",
        "        best_score = original_pred\n",
        "        for feature_idx in range(X_instance.shape[1]):\n",
        "            # Try increasing feature\n",
        "            test_cf = counterfactual.copy()\n",
        "            step = (feature_ranges[feature_idx][1] - feature_ranges[feature_idx][0]) * 0.1\n",
        "            test_cf[0, feature_idx] = min(\n",
        "                test_cf[0, feature_idx] + step,\n",
        "                feature_ranges[feature_idx][1]\n",
        "            )\n",
        "            new_pred = model.predict_proba(test_cf)[0, 1]\n",
        "            # Check if we're moving toward target class\n",
        "            if target_class == 1 and new_pred > best_score:\n",
        "                best_score = new_pred\n",
        "                best_change = (feature_idx, step)\n",
        "            elif target_class == 0 and new_pred < best_score:\n",
        "                best_score = new_pred\n",
        "                best_change = (feature_idx, -step)\n",
        "        if best_change is None:\n",
        "            break\n",
        "        # Apply best change\n",
        "        feature_idx, change = best_change\n",
        "        counterfactual[0, feature_idx] += change\n",
        "        counterfactual[0, feature_idx] = np.clip(\n",
        "            counterfactual[0, feature_idx],\n",
        "            feature_ranges[feature_idx][0],\n",
        "            feature_ranges[feature_idx][1]\n",
        "        )\n",
        "        # Check if we've reached target class\n",
        "        new_pred = model.predict_proba(counterfactual)[0, 1]\n",
        "        new_class = model.predict(counterfactual)[0]\n",
        "        if new_class == target_class:\n",
        "            return counterfactual, iteration + 1, \"Target class reached\"\n",
        "    return counterfactual, max_iterations, \"Max iterations reached\"\n",
        "# ============================================================================\n",
        "# WHAT-IF ANALYSIS\n",
        "# ============================================================================\n",
        "def what_if_analysis(model, X_instance, feature_names, feature_to_change, values_to_test):\n",
        "    \"\"\"\n",
        "    Perform what-if analysis by changing a single feature\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    for value in values_to_test:\n",
        "        X_test = X_instance.copy()\n",
        "        feature_idx = feature_names.index(feature_to_change)\n",
        "        X_test[0, feature_idx] = value\n",
        "        pred_proba = model.predict_proba(X_test)[0, 1]\n",
        "        pred_class = model.predict(X_test)[0]\n",
        "        results.append({\n",
        "            'value': value,\n",
        "            'prediction_probability': pred_proba,\n",
        "            'prediction_class': pred_class\n",
        "        })\n",
        "    return pd.DataFrame(results)\n",
        "# ============================================================================\n",
        "# GENERATE DATASET\n",
        "# ============================================================================\n",
        "def generate_dataset(n_samples=1000):\n",
        "    \"\"\"\n",
        "    Generate synthetic dataset for counterfactual analysis\n",
        "    \"\"\"\n",
        "    np.random.seed(42)\n",
        "    age = np.random.randint(25, 70, n_samples)\n",
        "    income = np.random.normal(60000, 25000, n_samples)\n",
        "    credit_score = np.random.normal(650, 100, n_samples)\n",
        "    debt_ratio = np.random.uniform(0.1, 0.6, n_samples)\n",
        "    approval_prob = (credit_score / 850 * 0.4 +\n",
        "                     (income / 100000) * 0.3 +\n",
        "                     (1 - debt_ratio) * 0.2 +\n",
        "                     (age / 70) * 0.1 +\n",
        "                     np.random.normal(0, 0.05, n_samples))\n",
        "    approval = (approval_prob > 0.5).astype(int)\n",
        "    df = pd.DataFrame({\n",
        "        'age': age,\n",
        "        'income': income,\n",
        "        'credit_score': credit_score,\n",
        "        'debt_ratio': debt_ratio,\n",
        "        'approved': approval\n",
        "    })\n",
        "    return df\n",
        "# ============================================================================\n",
        "# VISUALIZATIONS\n",
        "# ============================================================================\n",
        "def plot_counterfactual_comparison(X_original, X_counterfactual, feature_names, original_pred, cf_pred):\n",
        "    \"\"\"\n",
        "    Plot comparison between original and counterfactual\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "    # Feature comparison\n",
        "    features = feature_names\n",
        "    original_values = X_original[0]\n",
        "    cf_values = X_counterfactual[0]\n",
        "    changes = cf_values - original_values\n",
        "    x = np.arange(len(features))\n",
        "    width = 0.35\n",
        "    axes[0].bar(x - width/2, original_values, width, label='Original', alpha=0.8, color='#e74c3c')\n",
        "    axes[0].bar(x + width/2, cf_values, width, label='Counterfactual', alpha=0.8, color='#2ecc71')\n",
        "    axes[0].set_xlabel('Features', fontsize=11, fontweight='bold')\n",
        "    axes[0].set_ylabel('Feature Values', fontsize=11, fontweight='bold')\n",
        "    axes[0].set_title('Original vs Counterfactual Feature Values', fontsize=12, fontweight='bold')\n",
        "    axes[0].set_xticks(x)\n",
        "    axes[0].set_xticklabels(features, rotation=15)\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(axis='y', alpha=0.3)\n",
        "    # Feature changes\n",
        "    colors = ['green' if c > 0 else 'red' for c in changes]\n",
        "    axes[1].barh(features, changes, color=colors, alpha=0.7)\n",
        "    axes[1].set_xlabel('Change in Feature Value', fontsize=11, fontweight='bold')\n",
        "    axes[1].set_title('Feature Changes to Achieve Counterfactual', fontsize=12, fontweight='bold')\n",
        "    axes[1].axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
        "    axes[1].grid(axis='x', alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('unit4-transparency-accountability', \n",
        "                dpi=300, bbox_inches='tight')\n",
        "    print(\"✅ Saved: counterfactual_comparison.png\")\n",
        "    plt.close()\n",
        "def plot_what_if_analysis(what_if_df, feature_name):\n",
        "    \"\"\"\n",
        "    Plot what-if analysis results\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    ax.plot(what_if_df['value'], what_if_df['prediction_probability'], \n",
        "           marker='o', linewidth=2, markersize=8, color='#3498db')\n",
        "    ax.axhline(y=0.5, color='red', linestyle='--', linewidth=1, label='Decision Threshold')\n",
        "    ax.set_xlabel(feature_name, fontsize=11, fontweight='bold')\n",
        "    ax.set_ylabel('Prediction Probability', fontsize=11, fontweight='bold')\n",
        "    ax.set_title(f'What-If Analysis: {feature_name}', fontsize=12, fontweight='bold')\n",
        "    ax.grid(alpha=0.3)\n",
        "    ax.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('unit4-transparency-accountability', \n",
        "                dpi=300, bbox_inches='tight')\n",
        "    print(\"✅ Saved: what_if_analysis.png\")\n",
        "    plt.close()\n",
        "# ============================================================================\n",
        "# MAIN EXECUTION\n",
        "# ============================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=\"*80)\n",
        "    print(\"Unit 4 - Example 3: Counterfactual Analysis\")\n",
        "    print(\"=\"*80)\n",
        "    # Generate dataset\n",
        "    print(\"\\nGenerating dataset...\")\n",
        "    df = generate_dataset(n_samples=1000)\n",
        "    print(f\"Dataset shape: {df.shape}\")\n",
        "    # Prepare data\n",
        "    feature_names = ['age', 'income', 'credit_score', 'debt_ratio']\n",
        "    X = df[feature_names].values\n",
        "    y = df['approved'].values\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.3, random_state=42, stratify=y\n",
        "    )\n",
        "    # Scale features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    # Train model\n",
        "    print(\"\\nTraining Random Forest model...\")\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    test_acc = accuracy_score(y_test, model.predict(X_test_scaled))\n",
        "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "    # Find a rejected instance to generate counterfactual\n",
        "    rejected_indices = np.where(model.predict(X_test_scaled) == 0)[0]\n",
        "    if len(rejected_indices) > 0:\n",
        "        sample_idx = rejected_indices[0]\n",
        "        X_instance = X_test_scaled[sample_idx:sample_idx+1]\n",
        "        print(f\"\\nOriginal instance (rejected):\")\n",
        "        print(f\"  Features: {dict(zip(feature_names, X_test[sample_idx]))}\")\n",
        "        print(f\"  Prediction probability: {model.predict_proba(X_instance)[0, 1]:.4f}\")\n",
        "        print(f\"  Prediction: {model.predict(X_instance)[0]}\")\n",
        "        # Generate counterfactual\n",
        "        print(\"\\nGenerating counterfactual (to get approved)...\")\n",
        "        X_counterfactual, iterations, status = generate_counterfactual(\n",
        "            model, X_instance, X_train_scaled, feature_names, target_class=1\n",
        "        )\n",
        "        print(f\"Counterfactual found after {iterations} iterations: {status}\")\n",
        "        print(f\"  Prediction probability: {model.predict_proba(X_counterfactual)[0, 1]:.4f}\")\n",
        "        print(f\"  Prediction: {model.predict(X_counterfactual)[0]}\")\n",
        "        # What-if analysis\n",
        "        print(\"\\nPerforming what-if analysis on credit_score...\")\n",
        "        credit_scores = np.linspace(500, 800, 50)\n",
        "        what_if_df = what_if_analysis(\n",
        "            model, X_instance, feature_names, 'credit_score', credit_scores\n",
        "        )\n",
        "        # Create visualizations\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"Creating Visualizations...\")\n",
        "        print(\"=\"*80)\n",
        "        original_pred = model.predict_proba(X_instance)[0, 1]\n",
        "        cf_pred = model.predict_proba(X_counterfactual)[0, 1]\n",
        "        plot_counterfactual_comparison(X_instance, X_counterfactual, feature_names, \n",
        "                                      original_pred, cf_pred)\n",
        "        plot_what_if_analysis(what_if_df, 'credit_score')\n",
        "    # Summary\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"SUMMARY\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"\\nKey Takeaways:\")\n",
        "    print(\"1. Counterfactuals show what needs to change to get a different outcome\")\n",
        "    print(\"2. What-if analysis explores how changes in features affect predictions\")\n",
        "    print(\"3. Counterfactuals help explain model decisions\")\n",
        "    print(\"4. Counterfactuals are useful for actionable insights\")\n",
        "    print(\"5. Counterfactual analysis improves model transparency\")\n",
        "    print(\"=\"*80 + \"\\n\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "course2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
