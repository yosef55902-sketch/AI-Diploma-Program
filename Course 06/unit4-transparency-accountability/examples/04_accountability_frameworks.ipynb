{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 4: Interpretability, Transparency, and Accountability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Unit 4 - Example 4: Accountability Frameworks\n",
      "================================================================================\n",
      "\n",
      "1. Stakeholder Responsibilities:\n",
      "\n",
      "Developers:\n",
      "  Accountability Level: 9\n",
      "  Responsibilities:\n",
      "    - Design fair and transparent algorithms\n",
      "    - Document model decisions and limitations\n",
      "    - Implement bias detection and mitigation\n",
      "    - Create model cards and documentation\n",
      "\n",
      "Data Scientists:\n",
      "  Accountability Level: 8\n",
      "  Responsibilities:\n",
      "    - Ensure data quality and representativeness\n",
      "    - Document data sources and preprocessing\n",
      "    - Identify potential biases in data\n",
      "    - Maintain data lineage\n",
      "\n",
      "Product Managers:\n",
      "  Accountability Level: 7\n",
      "  Responsibilities:\n",
      "    - Define ethical requirements\n",
      "    - Oversee deployment and monitoring\n",
      "    - Ensure compliance with regulations\n",
      "    - Manage stakeholder communication\n",
      "\n",
      "Legal:\n",
      "  Accountability Level: 9\n",
      "  Responsibilities:\n",
      "    - Ensure regulatory compliance\n",
      "    - Review model for legal risks\n",
      "    - Handle liability issues\n",
      "    - Manage data privacy requirements\n",
      "\n",
      "End Users:\n",
      "  Accountability Level: 5\n",
      "  Responsibilities:\n",
      "    - Use AI system responsibly\n",
      "    - Report issues and biases\n",
      "    - Provide feedback\n",
      "    - Understand system limitations\n",
      "\n",
      "2. Model Card:\n",
      "  Model: Loan Approval Classifier\n",
      "  Created: 2025-11-30\n",
      "  Performance: {'accuracy': 0.87, 'fairness_score': 0.92}\n",
      "\n",
      "3. Audit Trail:\n",
      "  Total audit entries: 7\n",
      "  Date range: 2025-10-31 23:14:22.175983 to 2025-11-12 23:14:22.175983\n",
      "\n",
      "4. Accountability Checklist:\n",
      "\n",
      "Pre-deployment:\n",
      "  [ ] Model documentation complete\n",
      "  [ ] Bias assessment performed\n",
      "  [ ] Fairness metrics calculated\n",
      "  [ ] Stakeholder review completed\n",
      "  [ ] Legal compliance verified\n",
      "\n",
      "Deployment:\n",
      "  [ ] Monitoring systems in place\n",
      "  [ ] Audit trail enabled\n",
      "  [ ] User notifications configured\n",
      "  [ ] Rollback plan prepared\n",
      "\n",
      "Post-deployment:\n",
      "  [ ] Regular performance monitoring\n",
      "  [ ] Fairness metrics tracking\n",
      "  [ ] User feedback collection\n",
      "  [ ] Periodic model audits\n",
      "  [ ] Incident response plan\n",
      "\n",
      "================================================================================\n",
      "Creating Visualizations...\n",
      "================================================================================\n",
      "✅ Saved: stakeholder_accountability.png\n",
      "✅ Saved: audit_timeline.png\n",
      "✅ Saved: accountability_checklist.png\n",
      "\n",
      "================================================================================\n",
      "SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Key Takeaways:\n",
      "1. Clear stakeholder responsibilities ensure accountability\n",
      "2. Model cards document model characteristics and limitations\n",
      "3. Audit trails track all system decisions and changes\n",
      "4. Accountability checklists ensure comprehensive coverage\n",
      "5. Accountability frameworks are essential for trustworthy AI\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Unit 4: Interpretability, Transparency, and Accountability\n",
    "Example 4: Accountability Frameworks\n",
    "This example demonstrates accountability frameworks for AI systems:\n",
    "- Key stakeholders and responsibilities\n",
    "- Mechanisms for tracking and auditing\n",
    "- Model cards and data sheets\n",
    "- Audit trails\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "sns.set_style(\"whitegrid\")\n",
    "# ============================================================================\n",
    "# STAKEHOLDER RESPONSIBILITIES\n",
    "# ============================================================================\n",
    "def define_stakeholder_responsibilities():\n",
    "    \"\"\"\n",
    "    Define key stakeholders and their responsibilities in AI accountability\n",
    "    \"\"\"\n",
    "    stakeholders = {\n",
    "        'Developers': {\n",
    "            'responsibilities': [\n",
    "                'Design fair and transparent algorithms',\n",
    "                'Document model decisions and limitations',\n",
    "                'Implement bias detection and mitigation',\n",
    "                'Create model cards and documentation'\n",
    "            ],\n",
    "            'accountability_level': 9\n",
    "        },\n",
    "        'Data Scientists': {\n",
    "            'responsibilities': [\n",
    "                'Ensure data quality and representativeness',\n",
    "                'Document data sources and preprocessing',\n",
    "                'Identify potential biases in data',\n",
    "                'Maintain data lineage'\n",
    "            ],\n",
    "            'accountability_level': 8\n",
    "        },\n",
    "        'Product Managers': {\n",
    "            'responsibilities': [\n",
    "                'Define ethical requirements',\n",
    "                'Oversee deployment and monitoring',\n",
    "                'Ensure compliance with regulations',\n",
    "                'Manage stakeholder communication'\n",
    "            ],\n",
    "            'accountability_level': 7\n",
    "        },\n",
    "        'Legal': {\n",
    "            'responsibilities': [\n",
    "                'Ensure regulatory compliance',\n",
    "                'Review model for legal risks',\n",
    "                'Handle liability issues',\n",
    "                'Manage data privacy requirements'\n",
    "            ],\n",
    "            'accountability_level': 9\n",
    "        },\n",
    "        'End Users': {\n",
    "            'responsibilities': [\n",
    "                'Use AI system responsibly',\n",
    "                'Report issues and biases',\n",
    "                'Provide feedback',\n",
    "                'Understand system limitations'\n",
    "            ],\n",
    "            'accountability_level': 5\n",
    "        }\n",
    "    }\n",
    "    return stakeholders\n",
    "# ============================================================================\n",
    "# MODEL CARD TEMPLATE\n",
    "# ============================================================================\n",
    "def create_model_card(model_name, model_type, performance_metrics, training_data_info, \n",
    "                     limitations, use_cases):\n",
    "    \"\"\"\n",
    "    Create a model card documenting key information about an AI model\n",
    "    \"\"\"\n",
    "    model_card = {\n",
    "        'model_name': model_name,\n",
    "        'model_type': model_type,\n",
    "        'date_created': datetime.now().strftime('%Y-%m-%d'),\n",
    "        'performance_metrics': performance_metrics,\n",
    "        'training_data': training_data_info,\n",
    "        'limitations': limitations,\n",
    "        'intended_use_cases': use_cases,\n",
    "        'ethical_considerations': {\n",
    "            'bias_mitigation': 'Applied reweighing and fairness constraints',\n",
    "            'transparency': 'SHAP and LIME explanations available',\n",
    "            'accountability': 'Full audit trail maintained'\n",
    "        }\n",
    "    }\n",
    "    return model_card\n",
    "# ============================================================================\n",
    "# AUDIT TRAIL\n",
    "# ============================================================================\n",
    "def create_audit_trail():\n",
    "    \"\"\"\n",
    "    Create an audit trail for AI system decisions\n",
    "    \"\"\"\n",
    "    audit_entries = []\n",
    "    # Simulate audit trail entries\n",
    "    base_time = datetime.now() - timedelta(days=30)\n",
    "    events = [\n",
    "        {'timestamp': base_time, 'event': 'Model trained', 'user': 'Data Scientist', 'details': 'Initial model training'},\n",
    "        {'timestamp': base_time + timedelta(days=1), 'event': 'Bias check performed', 'user': 'Developer', 'details': 'Demographic parity: 0.05'},\n",
    "        {'timestamp': base_time + timedelta(days=2), 'event': 'Model deployed', 'user': 'Product Manager', 'details': 'Production deployment'},\n",
    "        {'timestamp': base_time + timedelta(days=5), 'event': 'Performance monitoring', 'user': 'System', 'details': 'Accuracy: 0.87'},\n",
    "        {'timestamp': base_time + timedelta(days=10), 'event': 'Bias detected', 'user': 'Monitoring System', 'details': 'Fairness metric degraded'},\n",
    "        {'timestamp': base_time + timedelta(days=11), 'event': 'Model retrained', 'user': 'Data Scientist', 'details': 'Retraining with fairness constraints'},\n",
    "        {'timestamp': base_time + timedelta(days=12), 'event': 'Model updated', 'user': 'Product Manager', 'details': 'New version deployed'},\n",
    "    ]\n",
    "    for event in events:\n",
    "        audit_entries.append({\n",
    "            'timestamp': event['timestamp'],\n",
    "            'event_type': event['event'],\n",
    "            'user': event['user'],\n",
    "            'details': event['details']\n",
    "        })\n",
    "    return pd.DataFrame(audit_entries)\n",
    "# ============================================================================\n",
    "# ACCOUNTABILITY FRAMEWORK\n",
    "# ============================================================================\n",
    "def accountability_framework_checklist():\n",
    "    \"\"\"\n",
    "    Create accountability framework checklist\n",
    "    \"\"\"\n",
    "    checklist = {\n",
    "        'Pre-deployment': [\n",
    "            'Model documentation complete',\n",
    "            'Bias assessment performed',\n",
    "            'Fairness metrics calculated',\n",
    "            'Stakeholder review completed',\n",
    "            'Legal compliance verified'\n",
    "        ],\n",
    "        'Deployment': [\n",
    "            'Monitoring systems in place',\n",
    "            'Audit trail enabled',\n",
    "            'User notifications configured',\n",
    "            'Rollback plan prepared'\n",
    "        ],\n",
    "        'Post-deployment': [\n",
    "            'Regular performance monitoring',\n",
    "            'Fairness metrics tracking',\n",
    "            'User feedback collection',\n",
    "            'Periodic model audits',\n",
    "            'Incident response plan'\n",
    "        ]\n",
    "    }\n",
    "    return checklist\n",
    "# ============================================================================\n",
    "# VISUALIZATIONS\n",
    "# ============================================================================\n",
    "def plot_stakeholder_responsibilities(stakeholders):\n",
    "    \"\"\"\n",
    "    Plot stakeholder responsibility matrix\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    names = list(stakeholders.keys())\n",
    "    accountability = [stakeholders[name]['accountability_level'] for name in names]\n",
    "    num_responsibilities = [len(stakeholders[name]['responsibilities']) for name in names]\n",
    "    scatter = ax.scatter(num_responsibilities, accountability, s=200, alpha=0.6, c=accountability, \n",
    "                        cmap='RdYlGn', edgecolors='black', linewidth=2)\n",
    "    for i, name in enumerate(names):\n",
    "        ax.annotate(name, (num_responsibilities[i], accountability[i]), \n",
    "                   xytext=(5, 5), textcoords='offset points', fontsize=10, fontweight='bold')\n",
    "    ax.set_xlabel('Number of Responsibilities', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Accountability Level (1-10)', fontsize=11, fontweight='bold')\n",
    "    ax.set_title('Stakeholder Accountability Matrix', fontsize=12, fontweight='bold')\n",
    "    ax.grid(alpha=0.3)\n",
    "    plt.colorbar(scatter, ax=ax, label='Accountability Level')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('unit4-transparency-accountability', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    print(\"✅ Saved: stakeholder_accountability.png\")\n",
    "    plt.close()\n",
    "def plot_audit_timeline(audit_df):\n",
    "    \"\"\"\n",
    "    Plot audit trail timeline\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    # Convert timestamps to days since first event\n",
    "    first_time = audit_df['timestamp'].min()\n",
    "    audit_df['days_since_start'] = (audit_df['timestamp'] - first_time).dt.days\n",
    "    # Plot events\n",
    "    event_types = audit_df['event_type'].unique()\n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, len(event_types)))\n",
    "    color_map = dict(zip(event_types, colors))\n",
    "    for idx, row in audit_df.iterrows():\n",
    "        ax.scatter(row['days_since_start'], idx, s=200, \n",
    "                 c=color_map[row['event_type']], alpha=0.7, edgecolors='black')\n",
    "        ax.text(row['days_since_start'], idx, f\"  {row['event_type']}\", \n",
    "               va='center', fontsize=9)\n",
    "    ax.set_xlabel('Days Since First Event', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Event Index', fontsize=11, fontweight='bold')\n",
    "    ax.set_title('AI System Audit Trail Timeline', fontsize=12, fontweight='bold')\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    # Legend\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [Patch(facecolor=color_map[et], label=et) for et in event_types]\n",
    "    ax.legend(handles=legend_elements, loc='upper left', fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('unit4-transparency-accountability', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    print(\"✅ Saved: audit_timeline.png\")\n",
    "    plt.close()\n",
    "def plot_accountability_checklist(checklist):\n",
    "    \"\"\"\n",
    "    Plot accountability checklist status\n",
    "    \"\"\"\n",
    "    phases = list(checklist.keys())\n",
    "    items_per_phase = [len(items) for items in checklist.values()]\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    bars = ax.bar(phases, items_per_phase, color=['#3498db', '#2ecc71', '#f39c12'], alpha=0.8)\n",
    "    # Add value labels\n",
    "    for bar, count in zip(bars, items_per_phase):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "               f'{int(count)} items',\n",
    "               ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Number of Checklist Items', fontsize=11, fontweight='bold')\n",
    "    ax.set_title('Accountability Framework Checklist by Phase', \n",
    "                fontsize=12, fontweight='bold')\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('unit4-transparency-accountability', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    print(\"✅ Saved: accountability_checklist.png\")\n",
    "    plt.close()\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\"*80)\n",
    "    print(\"Unit 4 - Example 4: Accountability Frameworks\")\n",
    "    print(\"=\"*80)\n",
    "    # Define stakeholders\n",
    "    print(\"\\n1. Stakeholder Responsibilities:\")\n",
    "    stakeholders = define_stakeholder_responsibilities()\n",
    "    for name, info in stakeholders.items():\n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"  Accountability Level: {info['accountability_level']}\")\n",
    "        print(f\"  Responsibilities:\")\n",
    "        for resp in info['responsibilities']:\n",
    "            print(f\"    - {resp}\")\n",
    "    # Create model card\n",
    "    print(\"\\n2. Model Card:\")\n",
    "    model_card = create_model_card(\n",
    "        model_name='Loan Approval Classifier',\n",
    "        model_type='Random Forest',\n",
    "        performance_metrics={'accuracy': 0.87, 'fairness_score': 0.92},\n",
    "        training_data_info={'samples': 10000, 'features': 10, 'date_range': '2023-01 to 2023-12'},\n",
    "        limitations=['May have bias for certain demographic groups', 'Requires periodic retraining'],\n",
    "        use_cases=['Loan approval decisions', 'Credit risk assessment']\n",
    "    )\n",
    "    print(f\"  Model: {model_card['model_name']}\")\n",
    "    print(f\"  Created: {model_card['date_created']}\")\n",
    "    print(f\"  Performance: {model_card['performance_metrics']}\")\n",
    "    # Create audit trail\n",
    "    print(\"\\n3. Audit Trail:\")\n",
    "    audit_df = create_audit_trail()\n",
    "    print(f\"  Total audit entries: {len(audit_df)}\")\n",
    "    print(f\"  Date range: {audit_df['timestamp'].min()} to {audit_df['timestamp'].max()}\")\n",
    "    # Accountability checklist\n",
    "    print(\"\\n4. Accountability Checklist:\")\n",
    "    checklist = accountability_framework_checklist()\n",
    "    for phase, items in checklist.items():\n",
    "        print(f\"\\n{phase}:\")\n",
    "        for item in items:\n",
    "            print(f\"  [ ] {item}\")\n",
    "    # Create visualizations\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Creating Visualizations...\")\n",
    "    print(\"=\"*80)\n",
    "    plot_stakeholder_responsibilities(stakeholders)\n",
    "    plot_audit_timeline(audit_df)\n",
    "    plot_accountability_checklist(checklist)\n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nKey Takeaways:\")\n",
    "    print(\"1. Clear stakeholder responsibilities ensure accountability\")\n",
    "    print(\"2. Model cards document model characteristics and limitations\")\n",
    "    print(\"3. Audit trails track all system decisions and changes\")\n",
    "    print(\"4. Accountability checklists ensure comprehensive coverage\")\n",
    "    print(\"5. Accountability frameworks are essential for trustworthy AI\")\n",
    "    print(\"=\"*80 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
