{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Fair Representation Learning | ØªØ¹Ù„Ù… Ø§Ù„ØªÙ…Ø«ÙŠÙ„ Ø§Ù„Ø¹Ø§Ø¯Ù„\n",
    "\n",
    "## ðŸ“š Prerequisites (What You Need First) | Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©\n",
    "\n",
    "**BEFORE starting this notebook**, you should have completed:\n",
    "- âœ… **Example 1: Bias Detection** - Understanding how to detect bias\n",
    "- âœ… **Example 2: Bias Mitigation** - Understanding mitigation techniques\n",
    "- âœ… **Basic Python knowledge**: Functions, data manipulation, ML concepts\n",
    "- âœ… **Understanding of neural networks**: Autoencoders, PCA (helpful but not required)\n",
    "\n",
    "**If you haven't completed these**, you might struggle with:\n",
    "- Understanding why fair representation matters\n",
    "- Knowing how to remove bias from feature representations\n",
    "- Understanding different fair representation techniques\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”— Where This Notebook Fits | Ù…ÙƒØ§Ù† Ù‡Ø°Ø§ Ø§Ù„Ø¯ÙØªØ±\n",
    "\n",
    "**This is the THIRD example in Unit 2** - it teaches you how to ensure fair representation in your data!\n",
    "\n",
    "**Why this example THIRD?**\n",
    "- **Before** you can ensure fair representation, you need to detect bias (Example 1)\n",
    "- **Before** you can learn fair representation, you need to understand mitigation (Example 2)\n",
    "- **Before** you can build fair systems, you need fair representation techniques\n",
    "\n",
    "**Builds on**: \n",
    "- ðŸ““ Example 1: Bias Detection (we detected bias)\n",
    "- ðŸ““ Example 2: Bias Mitigation (we learned to fix bias)\n",
    "\n",
    "**Leads to**: \n",
    "- ðŸ““ Example 4: Bias Case Studies (analyzing real bias cases)\n",
    "- ðŸ““ Example 5: Fair AI Development (building fair AI systems)\n",
    "\n",
    "**Why this order?**\n",
    "1. Fair representation provides **data-level solutions** (complements mitigation)\n",
    "2. Fair representation teaches **feature transformation** (critical skill)\n",
    "3. Fair representation shows **advanced techniques** (PCA, autoencoders, adversarial)\n",
    "\n",
    "---\n",
    "\n",
    "## The Story: Fair Features for Fair Models | Ø§Ù„Ù‚ØµØ©: Ù…ÙŠØ²Ø§Øª Ø¹Ø§Ø¯Ù„Ø© Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¹Ø§Ø¯Ù„Ø©\n",
    "\n",
    "Imagine you're a chef preparing ingredients. **Before** cooking, you need to prepare ingredients properly - wash vegetables, remove spoiled parts, cut uniformly. **After** preparation, you have clean, uniform ingredients that make better dishes!\n",
    "\n",
    "Same with AI: **Before** we have features that may contain bias, now we transform them to remove bias - use PCA, autoencoders, or adversarial techniques. **After** fair representation, we have features that don't encode bias!\n",
    "\n",
    "---\n",
    "\n",
    "## Why Fair Representation Matters | Ù„Ù…Ø§Ø°Ø§ ÙŠÙ‡Ù… Ø§Ù„ØªÙ…Ø«ÙŠÙ„ Ø§Ù„Ø¹Ø§Ø¯Ù„ØŸ\n",
    "\n",
    "Fair representation is essential for ethical AI:\n",
    "- **Remove Bias from Features**: Transform features to remove sensitive information\n",
    "- **Better Generalization**: Fair features lead to more generalizable models\n",
    "- **Privacy Protection**: Remove sensitive information from representations\n",
    "- **Compliance**: Meet fairness requirements at the data level\n",
    "- **Foundation for Fairness**: Fair representation is the foundation for fair models\n",
    "\n",
    "## Learning Objectives | Ø£Ù‡Ø¯Ø§Ù Ø§Ù„ØªØ¹Ù„Ù…\n",
    "1. Understand what fair representation means\n",
    "2. Learn PCA for bias removal\n",
    "3. Learn autoencoders for feature transformation\n",
    "4. Learn adversarial debiasing techniques\n",
    "5. Compare effectiveness of different fair representation methods\n",
    "6. Understand when to use each technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "# These libraries help us implement fair representation learning techniques\n",
    "\n",
    "import numpy as np  # For numerical operations: Arrays, calculations, random number generation\n",
    "import pandas as pd  # For data manipulation: DataFrames, data analysis\n",
    "import matplotlib.pyplot as plt  # For creating visualizations: Charts, graphs, comparisons\n",
    "import seaborn as sns  # For statistical visualizations: Heatmaps, advanced plots\n",
    "from sklearn.model_selection import train_test_split  # For splitting data: Separate training and testing sets\n",
    "from sklearn.decomposition import PCA  # For dimensionality reduction: Principal Component Analysis\n",
    "from sklearn.preprocessing import StandardScaler  # For data preprocessing: Feature scaling\n",
    "from sklearn.ensemble import RandomForestClassifier  # For ML model: Classification algorithm\n",
    "from sklearn.metrics import accuracy_score  # For model evaluation: Accuracy metric\n",
    "from sklearn.neural_network import MLPRegressor  # For neural networks: Autoencoder implementation\n",
    "import warnings  # For suppressing warnings: Clean output\n",
    "import os  # For file operations: Saving images\n",
    "\n",
    "# Suppress warnings: Clean output (neural networks may show warnings)\n",
    "warnings.filterwarnings('ignore')  # Ignore warnings: Suppress non-critical warnings\n",
    "\n",
    "# Configure plotting: Set default styles for better visualizations\n",
    "plt.rcParams['font.size'] = 10  # Font size: Make text readable (10pt is good for most displays)\n",
    "plt.rcParams['figure.figsize'] = (14, 8)  # Figure size: 14 inches wide, 8 inches tall (good for detailed charts)\n",
    "sns.set_style(\"whitegrid\")  # Style: White background with grid for clean look\n",
    "\n",
    "print(\" Libraries imported successfully!\")\n",
    "print(\"\\nðŸ“š What each library does:\")\n",
    "print(\"   - numpy/pandas: Data manipulation and numerical operations\")\n",
    "print(\"   - matplotlib/seaborn: Create visualizations (charts, heatmaps)\")\n",
    "print(\"   - sklearn: Machine learning (PCA, models, metrics, preprocessing)\")\n",
    "print(\"   - sklearn.neural_network: Neural networks (autoencoders)\")\n",
    "print(\"   - os: File operations (saving images)\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Generate synthetic dataset with features correlated with sensitive attribute\n",
    "# This creates data where features encode information about sensitive attributes\n",
    "\n",
    "# BEFORE: No data with feature-sensitive correlation to practice on\n",
    "# AFTER: We'll have a dataset with intentional correlation\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸ“Š GENERATING BIASED DATASET\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nWe'll create a dataset where:\")\n",
    "print(\"  - Features X1 and X2 are correlated with sensitive attribute\")\n",
    "print(\"  - This simulates real-world bias in feature representations\")\n",
    "print(\"  - We'll use this to practice fair representation techniques\\n\")\n",
    "\n",
    "def generate_biased_dataset(n_samples=2000):\n",
    "    pass\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Summary: What We Learned | Ø§Ù„Ù…Ù„Ø®Øµ: Ù…Ø§ ØªØ¹Ù„Ù…Ù†Ø§Ù‡\n",
    "\n",
    "**BEFORE this notebook**: We knew how to detect and mitigate bias, but features may still encode sensitive information.\n",
    "\n",
    "**AFTER this notebook**: We can:\n",
    "- âœ… Understand what fair representation means\n",
    "- âœ… Use PCA to remove correlation with sensitive attributes\n",
    "- âœ… Use autoencoders for feature transformation\n",
    "- âœ… Understand adversarial debiasing techniques\n",
    "- âœ… Compare effectiveness of different fair representation methods\n",
    "- âœ… Choose the right technique for different scenarios\n",
    "\n",
    "### Key Takeaways | Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©\n",
    "\n",
    "1. **Fair Representation**: Transform features to remove bias at the data level\n",
    "2. **PCA**: Can reduce correlation with sensitive attributes through dimensionality reduction\n",
    "3. **Autoencoders**: Learn compressed representations that may remove sensitive information\n",
    "4. **Adversarial Debiasing**: Makes it hard to predict sensitive attributes from features\n",
    "5. **Trade-offs**: Balance between fairness and predictive performance\n",
    "\n",
    "### Next Steps | Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©\n",
    "\n",
    "- ðŸ““ **Example 4**: Bias Case Studies (analyze real-world bias cases!)\n",
    "- ðŸ““ **Example 5**: Fair AI Development (build fair AI systems from the start!)\n",
    "\n",
    "---\n",
    "\n",
    "**Congratulations!** ðŸŽ‰ You've learned how to ensure fair representation in your features!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 2: Understanding Fair Representation | Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø«Ø§Ù†ÙŠ: ÙÙ‡Ù… Ø§Ù„ØªÙ…Ø«ÙŠÙ„ Ø§Ù„Ø¹Ø§Ø¯Ù„\n",
    "\n",
    "### ðŸ“š Prerequisites (What You Need First)\n",
    "-  **Library imports** (from Part 1) - Understanding ML and neural network tools\n",
    "-  **Understanding of bias** (from Examples 1-2) - Knowing what bias looks like\n",
    "\n",
    "### ðŸ”— Relationship: What This Builds On\n",
    "This builds on bias detection and mitigation - we now ensure features are fair!\n",
    "- Builds on: Bias detection skills, understanding of mitigation\n",
    "- Shows: How to transform features to remove bias\n",
    "\n",
    "### ðŸ“– The Story\n",
    "**Before fair representation**: We have features that may encode bias.\n",
    "**After fair representation**: We have transformed features that don't encode sensitive information!\n",
    "\n",
    "---\n",
    "\n",
    "## Step 2: Generate Biased Dataset | Ø§Ù„Ø®Ø·ÙˆØ© 2: Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØªØ­ÙŠØ²Ø©\n",
    "\n",
    "**BEFORE**: We need data with features correlated with sensitive attributes.\n",
    "\n",
    "**AFTER**: We'll create a dataset where features are correlated with sensitive attributes, so we can practice removing that correlation!\n",
    "\n",
    "**Why generate biased data?** Allows us to:\n",
    "- Control the correlation between features and sensitive attributes\n",
    "- Practice fair representation techniques safely\n",
    "- Compare before/after correlation\n",
    "    \"\"\"\n",
    "    Generate dataset with features correlated with sensitive attribute.\n",
    "    \n",
    "    HOW IT WORKS:\n",
    "    1. Creates sensitive attribute (two groups)\n",
    "    2. Generates features where some are correlated with sensitive attribute\n",
    "    3. Creates target variable based on features\n",
    "    4. Returns DataFrame with features, sensitive attribute, and target\n",
    "    \n",
    "    â° WHEN to use: To create test data with known feature-sensitive correlation\n",
    "    ðŸ’¡ WHY use: Allows us to practice fair representation on data where we know correlation exists\n",
    "    \"\"\"\n",
    "    # Set random seed: Ensure reproducible results\n",
    "    np.random.seed(42)  # Seed value: Makes random numbers predictable for consistency\n",
    "    \n",
    "    # Create sensitive attribute: Two groups (0 = Group A, 1 = Group B)\n",
    "    # Why sensitive attribute? This is what we want to remove from features\n",
    "    sensitive = np.random.binomial(1, 0.5, n_samples)  # Binary: 50% chance of each group\n",
    "    \n",
    "    # Generate features: Some correlated with sensitive attribute\n",
    "    # Why correlation? Simulates real-world bias where features encode sensitive information\n",
    "    X1 = np.random.normal(0, 1, n_samples) + 0.5 * sensitive  # Feature 1: Correlated with sensitive (0.5 coefficient)\n",
    "    X2 = np.random.normal(0, 1, n_samples) + 0.3 * sensitive  # Feature 2: Correlated with sensitive (0.3 coefficient)\n",
    "    X3 = np.random.normal(0, 1, n_samples)  # Feature 3: Independent of sensitive attribute\n",
    "    X4 = np.random.normal(0, 1, n_samples)  # Feature 4: Independent of sensitive attribute\n",
    "    \n",
    "    # Create target variable: Based on features (should be independent of sensitive after fair representation)\n",
    "    # Why this formula? Creates realistic relationship between features and target\n",
    "    y = (0.4 * X1 + 0.3 * X2 + 0.2 * X3 + 0.1 * X4 + np.random.normal(0, 0.1, n_samples) > 0).astype(int)  # Binary: 1 if weighted sum > 0\n",
    "    \n",
    "    # Create DataFrame: Organize data for analysis\n",
    "    df = pd.DataFrame({\n",
    "        'feature1': X1,  # Feature 1: Correlated with sensitive\n",
    "        'feature2': X2,  # Feature 2: Correlated with sensitive\n",
    "        'feature3': X3,  # Feature 3: Independent\n",
    "        'feature4': X4,  # Feature 4: Independent\n",
    "        'sensitive': sensitive,  # Sensitive: Group membership (protected attribute)\n",
    "        'target': y  # Target: Outcome we want to predict\n",
    "    })\n",
    "    \n",
    "    return df  # Return: DataFrame with features, sensitive attribute, and target\n",
    "\n",
    "# Generate the biased dataset\n",
    "print(\"Generating synthetic biased dataset...\")\n",
    "df = generate_biased_dataset(n_samples=2000)\n",
    "print(f\" Generated dataset with {len(df)} samples\")\n",
    "print(f\"   Features correlated with sensitive: X1, X2\")\n",
    "print(f\"   Features independent of sensitive: X3, X4\")\n",
    "print(\"   (We'll use fair representation to remove correlation!)\")\n",
    "# ============================================================================\n",
    "# FAIR REPRESENTATION USING PCA\n",
    "# ============================================================================\n",
    "def fair_representation_pca(X, sensitive, n_components=2):\n",
    "    \"\"\"\n",
    "    Use PCA to remove correlation with sensitive attribute\n",
    "    \"\"\"\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_transformed = pca.fit_transform(X_scaled)\n",
    "    # Check correlation with sensitive attribute\n",
    "    correlations = []\n",
    "    for i in range(n_components):\n",
    "        corr = np.abs(np.corrcoef(X_transformed[:, i], sensitive)[0, 1])\n",
    "        correlations.append(corr)\n",
    "    return X_transformed, correlations, pca, scaler\n",
    "# ============================================================================\n",
    "# FAIR REPRESENTATION USING AUTOENCODER\n",
    "# ============================================================================\n",
    "def create_autoencoder(input_dim, encoding_dim=2):\n",
    "    \"\"\"\n",
    "    Create a simple autoencoder for fair representation\n",
    "    \"\"\"\n",
    "    # Simple MLP-based autoencoder\n",
    "    encoder = MLPRegressor(\n",
    "        hidden_layer_sizes=(input_dim, encoding_dim),\n",
    "        activation='relu',\n",
    "        solver='adam',\n",
    "        max_iter=500,\n",
    "        random_state=42\n",
    "    )\n",
    "    decoder = MLPRegressor(\n",
    "        hidden_layer_sizes=(encoding_dim, input_dim),\n",
    "        activation='relu',\n",
    "        solver='adam',\n",
    "        max_iter=500,\n",
    "        random_state=42\n",
    "    )\n",
    "    return encoder, decoder\n",
    "def train_autoencoder(X, encoding_dim=2):\n",
    "    \"\"\"\n",
    "    Train autoencoder to learn fair representation\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    encoder, decoder = create_autoencoder(X.shape[1], encoding_dim)\n",
    "    # Train encoder-decoder\n",
    "    encoder.fit(X_scaled, X_scaled)\n",
    "    encoded = encoder.predict(X_scaled)\n",
    "    decoder.fit(encoded, X_scaled)\n",
    "    return encoder, decoder, scaler, encoded\n",
    "# ============================================================================\n",
    "# ADVERSARIAL DEBIASING (SIMPLIFIED)\n",
    "# ============================================================================\n",
    "def adversarial_debiasing_simple(X, y, sensitive, epochs=100):\n",
    "    \"\"\"\n",
    "    Simplified adversarial debiasing approach\n",
    "    Main model predicts target, adversary predicts sensitive attribute\n",
    "    Goal: Make it hard for adversary to predict sensitive attribute\n",
    "    \"\"\"\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    # Main model (predicts target)\n",
    "    main_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    main_model.fit(X_scaled, y)\n",
    "    # Adversary model (tries to predict sensitive attribute from main model's features)\n",
    "    # In practice, this would be trained adversarially\n",
    "    adversary = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    adversary.fit(X_scaled, sensitive)\n",
    "    # Measure how well adversary can predict sensitive attribute\n",
    "    adversary_pred = adversary.predict(X_scaled)\n",
    "    adversary_acc = accuracy_score(sensitive, adversary_pred)\n",
    "    return main_model, adversary, scaler, adversary_acc\n",
    "# ============================================================================\n",
    "# EVALUATION\n",
    "# ============================================================================\n",
    "def evaluate_fairness(X_transformed, sensitive, method_name):\n",
    "    \"\"\"\n",
    "    Evaluate how well the transformation removes correlation with sensitive attribute\n",
    "    \"\"\"\n",
    "    correlations = []\n",
    "    for i in range(X_transformed.shape[1]):\n",
    "        corr = np.abs(np.corrcoef(X_transformed[:, i], sensitive)[0, 1])\n",
    "        correlations.append(corr)\n",
    "    avg_correlation = np.mean(correlations)\n",
    "    max_correlation = np.max(correlations)\n",
    "    print(f\"\\n{method_name}:\")\n",
    "    print(f\"  Average correlation with sensitive attribute: {avg_correlation:.4f}\")\n",
    "    print(f\"  Maximum correlation: {max_correlation:.4f}\")\n",
    "    return avg_correlation, max_correlation\n",
    "def compare_representations(df):\n",
    "    \"\"\"\n",
    "    Compare different fair representation learning methods\n",
    "    \"\"\"\n",
    "    X = df[['feature1', 'feature2', 'feature3', 'feature4']].values\n",
    "    y = df['target'].values\n",
    "    sensitive = df['sensitive'].values\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test, sensitive_train, sensitive_test = train_test_split(\n",
    "        X, y, sensitive, test_size=0.3, random_state=42, stratify=y\n",
    "    )\n",
    "    results = {}\n",
    "    # 1. Original features (baseline)\n",
    "    print(\"=\"*80)\n",
    "    print(\"1. BASELINE: Original Features\")\n",
    "    print(\"=\"*80)\n",
    "    corr_orig = []\n",
    "    for i in range(X_train.shape[1]):\n",
    "        corr = np.abs(np.corrcoef(X_train[:, i], sensitive_train)[0, 1])\n",
    "        corr_orig.append(corr)\n",
    "    print(f\"Average correlation with sensitive attribute: {np.mean(corr_orig):.4f}\")\n",
    "    # Train classifier on original features\n",
    "    scaler_orig = StandardScaler()\n",
    "    X_train_scaled = scaler_orig.fit_transform(X_train)\n",
    "    X_test_scaled = scaler_orig.transform(X_test)\n",
    "    model_orig = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model_orig.fit(X_train_scaled, y_train)\n",
    "    acc_orig = accuracy_score(y_test, model_orig.predict(X_test_scaled))\n",
    "    print(f\"Classification accuracy: {acc_orig:.4f}\")\n",
    "    results['Original'] = {\n",
    "        'correlation': np.mean(corr_orig),\n",
    "        'accuracy': acc_orig,\n",
    "        'features': X_train_scaled\n",
    "    }\n",
    "    # 2. PCA-based fair representation\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"2. PCA-BASED FAIR REPRESENTATION\")\n",
    "    print(\"=\"*80)\n",
    "    X_pca, correlations, pca, scaler_pca = fair_representation_pca(X_train, sensitive_train, n_components=2)\n",
    "    avg_corr, max_corr = evaluate_fairness(X_pca, sensitive_train, \"PCA\")\n",
    "    # Train classifier on PCA features\n",
    "    X_test_pca = pca.transform(scaler_pca.transform(X_test))\n",
    "    model_pca = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model_pca.fit(X_pca, y_train)\n",
    "    acc_pca = accuracy_score(y_test, model_pca.predict(X_test_pca))\n",
    "    print(f\"Classification accuracy: {acc_pca:.4f}\")\n",
    "    results['PCA'] = {\n",
    "        'correlation': avg_corr,\n",
    "        'accuracy': acc_pca,\n",
    "        'features': X_pca\n",
    "    }\n",
    "    # 3. Autoencoder-based fair representation\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"3. AUTOENCODER-BASED FAIR REPRESENTATION\")\n",
    "    print(\"=\"*80)\n",
    "    encoder, decoder, scaler_ae, X_encoded = train_autoencoder(X_train, encoding_dim=2)\n",
    "    avg_corr, max_corr = evaluate_fairness(X_encoded, sensitive_train, \"Autoencoder\")\n",
    "    # Train classifier on encoded features\n",
    "    X_test_encoded = encoder.predict(scaler_ae.transform(X_test))\n",
    "    model_ae = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model_ae.fit(X_encoded, y_train)\n",
    "    acc_ae = accuracy_score(y_test, model_ae.predict(X_test_encoded))\n",
    "    print(f\"Classification accuracy: {acc_ae:.4f}\")\n",
    "    results['Autoencoder'] = {\n",
    "        'correlation': avg_corr,\n",
    "        'accuracy': acc_ae,\n",
    "        'features': X_encoded\n",
    "    }\n",
    "    # 4. Adversarial debiasing\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"4. ADVERSARIAL DEBIASING\")\n",
    "    print(\"=\"*80)\n",
    "    main_model, adversary, scaler_adv, adv_acc = adversarial_debiasing_simple(\n",
    "        X_train, y_train, sensitive_train\n",
    "    )\n",
    "    print(f\"Adversary accuracy (predicting sensitive attribute): {adv_acc:.4f}\")\n",
    "    print(f\"Main model accuracy: {accuracy_score(y_test, main_model.predict(scaler_adv.transform(X_test))):.4f}\")\n",
    "    results['Adversarial'] = {\n",
    "        'correlation': adv_acc,  # Adversary accuracy as proxy\n",
    "        'accuracy': accuracy_score(y_test, main_model.predict(scaler_adv.transform(X_test))),\n",
    "        'features': scaler_adv.transform(X_train)\n",
    "    }\n",
    "    return results\n",
    "# ============================================================================\n",
    "# VISUALIZATIONS\n",
    "# ============================================================================\n",
    "def plot_correlation_comparison(results):\n",
    "    \"\"\"\n",
    "    Plot correlation comparison across methods\n",
    "    \"\"\"\n",
    "    methods = list(results.keys())\n",
    "    correlations = [results[m]['correlation'] for m in methods]\n",
    "    accuracies = [results[m]['accuracy'] for m in methods]\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    # Correlation plot\n",
    "    axes[0].bar(methods, correlations, color=['#e74c3c', '#3498db', '#2ecc71', '#f39c12'])\n",
    "    axes[0].set_title('Correlation with Sensitive Attribute (Lower is Better)', \n",
    "                     fontsize=12, fontweight='bold')\n",
    "    axes[0].set_ylabel('Correlation')\n",
    "    axes[0].tick_params(axis='x', rotation=15)\n",
    "    axes[0].grid(axis='y', alpha=0.3)\n",
    "    # Accuracy plot\n",
    "    axes[1].bar(methods, accuracies, color=['#e74c3c', '#3498db', '#2ecc71', '#f39c12'])\n",
    "    axes[1].set_title('Classification Accuracy', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].tick_params(axis='x', rotation=15)\n",
    "    axes[1].grid(axis='y', alpha=0.3)\n",
    "    axes[1].set_ylim([0, 1])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('unit2-bias-justice', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    print(\"\\n Saved: fair_representation_comparison.png\")\n",
    "    plt.close()\n",
    "def plot_feature_space(results, sensitive):\n",
    "    \"\"\"\n",
    "    Plot 2D feature space for PCA and Autoencoder\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    # PCA features\n",
    "    if 'PCA' in results and results['PCA']['features'].shape[1] >= 2:\n",
    "        pca_features = results['PCA']['features']\n",
    "        scatter = axes[0].scatter(pca_features[:, 0], pca_features[:, 1], \n",
    "                                 c=sensitive, cmap='coolwarm', alpha=0.6)\n",
    "        axes[0].set_title('PCA Feature Space', fontsize=12, fontweight='bold')\n",
    "        axes[0].set_xlabel('First Principal Component')\n",
    "        axes[0].set_ylabel('Second Principal Component')\n",
    "        axes[0].grid(alpha=0.3)\n",
    "        plt.colorbar(scatter, ax=axes[0], label='Sensitive Attribute')\n",
    "    # Autoencoder features\n",
    "    if 'Autoencoder' in results and results['Autoencoder']['features'].shape[1] >= 2:\n",
    "        ae_features = results['Autoencoder']['features']\n",
    "        scatter = axes[1].scatter(ae_features[:, 0], ae_features[:, 1], \n",
    "                                 c=sensitive, cmap='coolwarm', alpha=0.6)\n",
    "        axes[1].set_title('Autoencoder Feature Space', fontsize=12, fontweight='bold')\n",
    "        axes[1].set_xlabel('First Encoded Dimension')\n",
    "        axes[1].set_ylabel('Second Encoded Dimension')\n",
    "        axes[1].grid(alpha=0.3)\n",
    "        plt.colorbar(scatter, ax=axes[1], label='Sensitive Attribute')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('unit2-bias-justice', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    print(\" Saved: fair_representation_feature_space.png\")\n",
    "    plt.close()\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\"*80)\n",
    "    print(\"Unit 2 - Example 3: Fair Representation Learning\")\n",
    "    print(\"=\"*80)\n",
    "    # Generate dataset\n",
    "    print(\"\\nGenerating biased dataset...\")\n",
    "    df = generate_biased_dataset(n_samples=2000)\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    # Compare methods\n",
    "    results = compare_representations(df)\n",
    "    # Create visualizations\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Creating Visualizations...\")\n",
    "    print(\"=\"*80)\n",
    "    plot_correlation_comparison(results)\n",
    "    plot_feature_space(results, df['sensitive'].values[:len(results['PCA']['features'])])\n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nKey Takeaways:\")\n",
    "    print(\"1. Fair representation learning transforms features to remove bias\")\n",
    "    print(\"2. PCA can reduce correlation with sensitive attributes\")\n",
    "    print(\"3. Autoencoders learn compressed representations\")\n",
    "    print(\"4. Adversarial debiasing makes it hard to predict sensitive attributes\")\n",
    "    print(\"5. Trade-off between fairness and predictive performance\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}